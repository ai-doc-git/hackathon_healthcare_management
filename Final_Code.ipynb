{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sought-barcelona",
   "metadata": {},
   "source": [
    "## AV Healthcare Analytics Hackathon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-riding",
   "metadata": {},
   "source": [
    "#### Import Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cross-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-journalist",
   "metadata": {},
   "source": [
    "#### Set the size of our seaborn plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(20,5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-understanding",
   "metadata": {},
   "source": [
    "#### Get the path of the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "objective-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = os.getcwd()\n",
    "train_path = pwd + \"\\\\train.csv\"\n",
    "test_path = pwd + \"\\\\test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-religion",
   "metadata": {},
   "source": [
    "#### Read the csv files and store in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wireless-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-excitement",
   "metadata": {},
   "source": [
    "#### Then, we will add a \"type\" column to both training and testing set, which will be used to separate our dataset after we concat them together to perform similar imputations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "human-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Type'] = 'Train'\n",
    "test_df['Type'] = 'Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "helpful-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_merged_df = pd.concat([train_df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-detection",
   "metadata": {},
   "source": [
    "#### We will use \"columns\" method to get the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "discrete-europe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['case_id', 'Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
       "       'Hospital_region_code', 'Available Extra Rooms in Hospital',\n",
       "       'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade',\n",
       "       'patientid', 'City_Code_Patient', 'Type of Admission',\n",
       "       'Severity of Illness', 'Visitors with Patient', 'Age',\n",
       "       'Admission_Deposit', 'Stay', 'Type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-trail",
   "metadata": {},
   "source": [
    "#### Now, we will create a Report of our entire dataset using pandas_profiling. It does Exploratory Data Analysis with just a few lines of code. It describes each feature in our dataset and checks for missing values, collinearity etc. and also creates visualizations for better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "persistent-noise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffad50e6ece24c4ab9273bf48c19aff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nkr4n\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\stats\\stats.py:4594: RuntimeWarning: overflow encountered in longlong_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fab27bac1a457ba83a70d35947518b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7dcffa904a04f15adb67dee41a99b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12da9cf08cc84c8b8182542c7ff339be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas_profiling as pp\n",
    "\n",
    "report = pp.ProfileReport(temp_merged_df)\n",
    "report.to_file(\"DataReport.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-utilization",
   "metadata": {},
   "source": [
    "#### Now, we will remove few columns from our dataset which will have no usecase in our predictive model such as \"case_id\" and \"patientid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "forty-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = ['Hospital_code', 'Hospital_type_code', 'City_Code_Hospital',\n",
    "       'Hospital_region_code', 'Available Extra Rooms in Hospital',\n",
    "       'Department', 'Ward_Type', 'Ward_Facility_Code', 'Bed Grade', 'City_Code_Patient', 'Type of Admission',\n",
    "       'Severity of Illness', 'Visitors with Patient', 'Age',\n",
    "       'Admission_Deposit', 'Stay', 'Type']\n",
    "merged_df = temp_merged_df[new_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-edmonton",
   "metadata": {},
   "source": [
    "#### Now we will check if our dataset has any missing values or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sustained-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hospital_code                             0\n",
       "Hospital_type_code                        0\n",
       "City_Code_Hospital                        0\n",
       "Hospital_region_code                      0\n",
       "Available Extra Rooms in Hospital         0\n",
       "Department                                0\n",
       "Ward_Type                                 0\n",
       "Ward_Facility_Code                        0\n",
       "Bed Grade                               148\n",
       "City_Code_Patient                      6689\n",
       "Type of Admission                         0\n",
       "Severity of Illness                       0\n",
       "Visitors with Patient                     0\n",
       "Age                                       0\n",
       "Admission_Deposit                         0\n",
       "Stay                                 137057\n",
       "Type                                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "increasing-overview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_code</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>City_Code_Hospital</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>Z</td>\n",
       "      <td>3</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Emergency</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4911.0</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>5</td>\n",
       "      <td>Z</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5954.0</td>\n",
       "      <td>41-50</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>2</td>\n",
       "      <td>anesthesia</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>4745.0</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>R</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>7272.0</td>\n",
       "      <td>41-50</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>b</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>radiotherapy</td>\n",
       "      <td>S</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Extreme</td>\n",
       "      <td>2</td>\n",
       "      <td>51-60</td>\n",
       "      <td>5558.0</td>\n",
       "      <td>41-50</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hospital_code Hospital_type_code  City_Code_Hospital Hospital_region_code  \\\n",
       "0              8                  c                   3                    Z   \n",
       "1              2                  c                   5                    Z   \n",
       "2             10                  e                   1                    X   \n",
       "3             26                  b                   2                    Y   \n",
       "4             26                  b                   2                    Y   \n",
       "\n",
       "   Available Extra Rooms in Hospital    Department Ward_Type  \\\n",
       "0                                  3  radiotherapy         R   \n",
       "1                                  2  radiotherapy         S   \n",
       "2                                  2    anesthesia         S   \n",
       "3                                  2  radiotherapy         R   \n",
       "4                                  2  radiotherapy         S   \n",
       "\n",
       "  Ward_Facility_Code  Bed Grade  City_Code_Patient Type of Admission  \\\n",
       "0                  F        2.0                7.0         Emergency   \n",
       "1                  F        2.0                7.0            Trauma   \n",
       "2                  E        2.0                7.0            Trauma   \n",
       "3                  D        2.0                7.0            Trauma   \n",
       "4                  D        2.0                7.0            Trauma   \n",
       "\n",
       "  Severity of Illness  Visitors with Patient    Age  Admission_Deposit   Stay  \\\n",
       "0             Extreme                      2  51-60             4911.0   0-10   \n",
       "1             Extreme                      2  51-60             5954.0  41-50   \n",
       "2             Extreme                      2  51-60             4745.0  31-40   \n",
       "3             Extreme                      2  51-60             7272.0  41-50   \n",
       "4             Extreme                      2  51-60             5558.0  41-50   \n",
       "\n",
       "    Type  \n",
       "0  Train  \n",
       "1  Train  \n",
       "2  Train  \n",
       "3  Train  \n",
       "4  Train  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-banana",
   "metadata": {},
   "source": [
    "#### Now we will use Simple Imputer from sklearn which replaces the missing values as per the specified strategy, i.e. mean, median, mode, most frequent etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seven-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(missing_values=np.nan,strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriented-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Bed Grade'] = imputer.fit_transform(merged_df[['Bed Grade']])\n",
    "merged_df['City_Code_Patient'] = imputer.fit_transform(merged_df[['City_Code_Patient']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-smith",
   "metadata": {},
   "source": [
    "#### We will one hot encode the following features to represent these categorical features to be more expressive and easier for the ML algorithms to understand and work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stopped-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_columns = ['Hospital_code', 'City_Code_Hospital',\n",
    "       'Hospital_region_code', 'Ward_Type', 'City_Code_Patient', 'Visitors with Patient', 'Age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "representative-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.get_dummies(data=merged_df,columns=onehot_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-default",
   "metadata": {},
   "source": [
    "#### Now, we will use Label Encoding to encode the below given features as these features are ordinal in nature and hence we want to assign labels to each item with some priorities associated with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "national-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "lencoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "overhead-significance",
   "metadata": {},
   "outputs": [],
   "source": [
    "lencode_columns = ['Hospital_type_code', 'Available Extra Rooms in Hospital',\n",
    "       'Department', 'Ward_Facility_Code', 'Bed Grade', 'Type of Admission', 'Severity of Illness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "monetary-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Hospital_type_code']= lencoder.fit_transform(merged_df['Hospital_type_code'])\n",
    "merged_df['Available Extra Rooms in Hospital']= lencoder.fit_transform(merged_df['Available Extra Rooms in Hospital'])\n",
    "merged_df['Department']= lencoder.fit_transform(merged_df['Department'])\n",
    "merged_df['Ward_Facility_Code']= lencoder.fit_transform(merged_df['Ward_Facility_Code'])\n",
    "merged_df['Bed Grade']= lencoder.fit_transform(merged_df['Bed Grade'])\n",
    "merged_df['Type of Admission']= lencoder.fit_transform(merged_df['Type of Admission'])\n",
    "merged_df['Severity of Illness']= lencoder.fit_transform(merged_df['Severity of Illness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-brake",
   "metadata": {},
   "source": [
    "#### We will use the \"describe()\" function to check for the distribution of the data in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "secure-miniature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Hospital_code_1</th>\n",
       "      <th>Hospital_code_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_0-10</th>\n",
       "      <th>Age_11-20</th>\n",
       "      <th>Age_21-30</th>\n",
       "      <th>Age_31-40</th>\n",
       "      <th>Age_41-50</th>\n",
       "      <th>Age_51-60</th>\n",
       "      <th>Age_61-70</th>\n",
       "      <th>Age_71-80</th>\n",
       "      <th>Age_81-90</th>\n",
       "      <th>Age_91-100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "      <td>455495.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.256501</td>\n",
       "      <td>3.196059</td>\n",
       "      <td>1.944024</td>\n",
       "      <td>3.286956</td>\n",
       "      <td>1.628215</td>\n",
       "      <td>0.782867</td>\n",
       "      <td>1.374033</td>\n",
       "      <td>4877.434022</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>0.015976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020066</td>\n",
       "      <td>0.052407</td>\n",
       "      <td>0.128563</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>0.200869</td>\n",
       "      <td>0.152594</td>\n",
       "      <td>0.106739</td>\n",
       "      <td>0.111389</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.532773</td>\n",
       "      <td>1.165920</td>\n",
       "      <td>0.561536</td>\n",
       "      <td>1.689726</td>\n",
       "      <td>0.871929</td>\n",
       "      <td>0.689184</td>\n",
       "      <td>0.768535</td>\n",
       "      <td>1084.982089</td>\n",
       "      <td>0.126924</td>\n",
       "      <td>0.125383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140227</td>\n",
       "      <td>0.222846</td>\n",
       "      <td>0.334716</td>\n",
       "      <td>0.398878</td>\n",
       "      <td>0.400651</td>\n",
       "      <td>0.359597</td>\n",
       "      <td>0.308781</td>\n",
       "      <td>0.314613</td>\n",
       "      <td>0.155137</td>\n",
       "      <td>0.064569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4738.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5405.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11920.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hospital_type_code  Available Extra Rooms in Hospital     Department  \\\n",
       "count       455495.000000                      455495.000000  455495.000000   \n",
       "mean             1.256501                           3.196059       1.944024   \n",
       "std              1.532773                           1.165920       0.561536   \n",
       "min              0.000000                           0.000000       0.000000   \n",
       "25%              0.000000                           2.000000       2.000000   \n",
       "50%              1.000000                           3.000000       2.000000   \n",
       "75%              2.000000                           4.000000       2.000000   \n",
       "max              6.000000                          17.000000       4.000000   \n",
       "\n",
       "       Ward_Facility_Code      Bed Grade  Type of Admission  \\\n",
       "count       455495.000000  455495.000000      455495.000000   \n",
       "mean             3.286956       1.628215           0.782867   \n",
       "std              1.689726       0.871929           0.689184   \n",
       "min              0.000000       0.000000           0.000000   \n",
       "25%              2.000000       1.000000           0.000000   \n",
       "50%              4.000000       2.000000           1.000000   \n",
       "75%              5.000000       2.000000           1.000000   \n",
       "max              5.000000       3.000000           2.000000   \n",
       "\n",
       "       Severity of Illness  Admission_Deposit  Hospital_code_1  \\\n",
       "count        455495.000000      455495.000000    455495.000000   \n",
       "mean              1.374033        4877.434022         0.016378   \n",
       "std               0.768535        1084.982089         0.126924   \n",
       "min               0.000000        1800.000000         0.000000   \n",
       "25%               1.000000        4184.000000         0.000000   \n",
       "50%               2.000000        4738.000000         0.000000   \n",
       "75%               2.000000        5405.000000         0.000000   \n",
       "max               2.000000       11920.000000         1.000000   \n",
       "\n",
       "       Hospital_code_2  ...       Age_0-10      Age_11-20      Age_21-30  \\\n",
       "count    455495.000000  ...  455495.000000  455495.000000  455495.000000   \n",
       "mean          0.015976  ...       0.020066       0.052407       0.128563   \n",
       "std           0.125383  ...       0.140227       0.222846       0.334716   \n",
       "min           0.000000  ...       0.000000       0.000000       0.000000   \n",
       "25%           0.000000  ...       0.000000       0.000000       0.000000   \n",
       "50%           0.000000  ...       0.000000       0.000000       0.000000   \n",
       "75%           0.000000  ...       0.000000       0.000000       0.000000   \n",
       "max           1.000000  ...       1.000000       1.000000       1.000000   \n",
       "\n",
       "           Age_31-40      Age_41-50      Age_51-60      Age_61-70  \\\n",
       "count  455495.000000  455495.000000  455495.000000  455495.000000   \n",
       "mean        0.198509       0.200869       0.152594       0.106739   \n",
       "std         0.398878       0.400651       0.359597       0.308781   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "           Age_71-80      Age_81-90     Age_91-100  \n",
       "count  455495.000000  455495.000000  455495.000000  \n",
       "mean        0.111389       0.024676       0.004187  \n",
       "std         0.314613       0.155137       0.064569  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       0.000000  \n",
       "50%         0.000000       0.000000       0.000000  \n",
       "75%         0.000000       0.000000       0.000000  \n",
       "max         1.000000       1.000000       1.000000  \n",
       "\n",
       "[8 rows x 136 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-mandate",
   "metadata": {},
   "source": [
    "#### As we can see that the \"Admission_Deposit\" feature is not having normal distribution of data, so we will plot a boxplot to check for outliers in this particular feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "comic-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Admission_Deposit'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=merged_df['Admission_Deposit'], data=merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-buffer",
   "metadata": {},
   "source": [
    "#### Treatment of Outliers by IQR method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "hungarian-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeOutlier(col):\n",
    "    sorted(col)\n",
    "    quant1,quant2 = col.quantile([0.20,0.80])\n",
    "    IQR = quant2 - quant1\n",
    "    lowerRange = quant1 - (1.5 * IQR)\n",
    "    upperRange = quant2 + (1.5 * IQR)\n",
    "    return lowerRange,upperRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "square-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowScore,highScore = removeOutlier(merged_df['Admission_Deposit'])\n",
    "merged_df['Admission_Deposit'] = np.where(merged_df['Admission_Deposit']>highScore,highScore,merged_df['Admission_Deposit'])\n",
    "merged_df['Admission_Deposit'] = np.where(merged_df['Admission_Deposit']<lowScore,lowScore,merged_df['Admission_Deposit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-theta",
   "metadata": {},
   "source": [
    "#### Now, as we can notice that the feature \"Admission_Deposit\" has values which are way higher than the rest of the feature values, which may create issues for the ML algorithm. Hence, we will scale this feature using MinMax Scaler within range of (0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "expanded-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "merged_df['Admission_Deposit'] = scaler.fit_transform(merged_df[['Admission_Deposit']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "respiratory-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Stay'] = merged_df['Stay'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bored-context",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "      <th>Type</th>\n",
       "      <th>...</th>\n",
       "      <th>Age_0-10</th>\n",
       "      <th>Age_11-20</th>\n",
       "      <th>Age_21-30</th>\n",
       "      <th>Age_31-40</th>\n",
       "      <th>Age_41-50</th>\n",
       "      <th>Age_51-60</th>\n",
       "      <th>Age_61-70</th>\n",
       "      <th>Age_71-80</th>\n",
       "      <th>Age_81-90</th>\n",
       "      <th>Age_91-100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.506348</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Train</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.676107</td>\n",
       "      <td>41-50</td>\n",
       "      <td>Train</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.479329</td>\n",
       "      <td>31-40</td>\n",
       "      <td>Train</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>41-50</td>\n",
       "      <td>Train</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.611654</td>\n",
       "      <td>41-50</td>\n",
       "      <td>Train</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hospital_type_code  Available Extra Rooms in Hospital  Department  \\\n",
       "0                   2                                  3           3   \n",
       "1                   2                                  2           3   \n",
       "2                   4                                  2           1   \n",
       "3                   1                                  2           3   \n",
       "4                   1                                  2           3   \n",
       "\n",
       "   Ward_Facility_Code  Bed Grade  Type of Admission  Severity of Illness  \\\n",
       "0                   5          1                  0                    0   \n",
       "1                   5          1                  1                    0   \n",
       "2                   4          1                  1                    0   \n",
       "3                   3          1                  1                    0   \n",
       "4                   3          1                  1                    0   \n",
       "\n",
       "   Admission_Deposit   Stay   Type  ...  Age_0-10  Age_11-20  Age_21-30  \\\n",
       "0           0.506348   0-10  Train  ...         0          0          0   \n",
       "1           0.676107  41-50  Train  ...         0          0          0   \n",
       "2           0.479329  31-40  Train  ...         0          0          0   \n",
       "3           0.890625  41-50  Train  ...         0          0          0   \n",
       "4           0.611654  41-50  Train  ...         0          0          0   \n",
       "\n",
       "   Age_31-40  Age_41-50  Age_51-60  Age_61-70  Age_71-80  Age_81-90  \\\n",
       "0          0          0          1          0          0          0   \n",
       "1          0          0          1          0          0          0   \n",
       "2          0          0          1          0          0          0   \n",
       "3          0          0          1          0          0          0   \n",
       "4          0          0          1          0          0          0   \n",
       "\n",
       "   Age_91-100  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-singing",
   "metadata": {},
   "source": [
    "#### Now, we will split our dataset into training and testing set using the flag that we had set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "anonymous-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = merged_df[merged_df['Type'] == 'Train']\n",
    "test = merged_df[merged_df['Type'] == 'Test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "driving-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['Stay']\n",
    "X = train.drop(columns=['Stay','Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minute-motion",
   "metadata": {},
   "source": [
    "#### Now, we will use CatBoostClassifier for this problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "silent-production",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "mediterranean-police",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.106164\n",
      "0:\tlearn: 2.2238070\ttotal: 726ms\tremaining: 12m 5s\n",
      "1:\tlearn: 2.1120798\ttotal: 1.17s\tremaining: 9m 42s\n",
      "2:\tlearn: 2.0238798\ttotal: 1.6s\tremaining: 8m 52s\n",
      "3:\tlearn: 1.9570892\ttotal: 2.05s\tremaining: 8m 29s\n",
      "4:\tlearn: 1.9020252\ttotal: 2.48s\tremaining: 8m 13s\n",
      "5:\tlearn: 1.8569438\ttotal: 2.91s\tremaining: 8m 2s\n",
      "6:\tlearn: 1.8205624\ttotal: 3.37s\tremaining: 7m 57s\n",
      "7:\tlearn: 1.7912304\ttotal: 3.8s\tremaining: 7m 51s\n",
      "8:\tlearn: 1.7652332\ttotal: 4.24s\tremaining: 7m 46s\n",
      "9:\tlearn: 1.7441399\ttotal: 4.67s\tremaining: 7m 42s\n",
      "10:\tlearn: 1.7257315\ttotal: 5.11s\tremaining: 7m 39s\n",
      "11:\tlearn: 1.7091019\ttotal: 5.54s\tremaining: 7m 36s\n",
      "12:\tlearn: 1.6954927\ttotal: 5.97s\tremaining: 7m 33s\n",
      "13:\tlearn: 1.6839591\ttotal: 6.4s\tremaining: 7m 30s\n",
      "14:\tlearn: 1.6737300\ttotal: 6.83s\tremaining: 7m 28s\n",
      "15:\tlearn: 1.6653915\ttotal: 7.31s\tremaining: 7m 29s\n",
      "16:\tlearn: 1.6568157\ttotal: 7.74s\tremaining: 7m 27s\n",
      "17:\tlearn: 1.6478584\ttotal: 8.18s\tremaining: 7m 26s\n",
      "18:\tlearn: 1.6416584\ttotal: 8.61s\tremaining: 7m 24s\n",
      "19:\tlearn: 1.6364697\ttotal: 9.04s\tremaining: 7m 23s\n",
      "20:\tlearn: 1.6308613\ttotal: 9.47s\tremaining: 7m 21s\n",
      "21:\tlearn: 1.6265763\ttotal: 9.9s\tremaining: 7m 19s\n",
      "22:\tlearn: 1.6220186\ttotal: 10.3s\tremaining: 7m 18s\n",
      "23:\tlearn: 1.6185614\ttotal: 10.8s\tremaining: 7m 17s\n",
      "24:\tlearn: 1.6142597\ttotal: 11.2s\tremaining: 7m 16s\n",
      "25:\tlearn: 1.6119513\ttotal: 11.6s\tremaining: 7m 15s\n",
      "26:\tlearn: 1.6079928\ttotal: 12.1s\tremaining: 7m 14s\n",
      "27:\tlearn: 1.6057038\ttotal: 12.5s\tremaining: 7m 13s\n",
      "28:\tlearn: 1.6029444\ttotal: 13s\tremaining: 7m 16s\n",
      "29:\tlearn: 1.6000072\ttotal: 13.5s\tremaining: 7m 15s\n",
      "30:\tlearn: 1.5982778\ttotal: 13.9s\tremaining: 7m 13s\n",
      "31:\tlearn: 1.5959757\ttotal: 14.3s\tremaining: 7m 13s\n",
      "32:\tlearn: 1.5938369\ttotal: 14.8s\tremaining: 7m 12s\n",
      "33:\tlearn: 1.5926281\ttotal: 15.2s\tremaining: 7m 11s\n",
      "34:\tlearn: 1.5910286\ttotal: 15.6s\tremaining: 7m 10s\n",
      "35:\tlearn: 1.5887590\ttotal: 16.1s\tremaining: 7m 10s\n",
      "36:\tlearn: 1.5877069\ttotal: 16.5s\tremaining: 7m 9s\n",
      "37:\tlearn: 1.5862110\ttotal: 16.9s\tremaining: 7m 8s\n",
      "38:\tlearn: 1.5849953\ttotal: 17.4s\tremaining: 7m 7s\n",
      "39:\tlearn: 1.5837970\ttotal: 17.8s\tremaining: 7m 6s\n",
      "40:\tlearn: 1.5821008\ttotal: 18.2s\tremaining: 7m 5s\n",
      "41:\tlearn: 1.5810153\ttotal: 18.6s\tremaining: 7m 5s\n",
      "42:\tlearn: 1.5800325\ttotal: 19.1s\tremaining: 7m 4s\n",
      "43:\tlearn: 1.5785248\ttotal: 19.5s\tremaining: 7m 3s\n",
      "44:\tlearn: 1.5767615\ttotal: 19.9s\tremaining: 7m 3s\n",
      "45:\tlearn: 1.5754457\ttotal: 20.4s\tremaining: 7m 2s\n",
      "46:\tlearn: 1.5746225\ttotal: 20.8s\tremaining: 7m 1s\n",
      "47:\tlearn: 1.5718145\ttotal: 21.2s\tremaining: 7m\n",
      "48:\tlearn: 1.5708273\ttotal: 21.7s\tremaining: 7m\n",
      "49:\tlearn: 1.5700574\ttotal: 22.1s\tremaining: 6m 59s\n",
      "50:\tlearn: 1.5688089\ttotal: 22.5s\tremaining: 6m 58s\n",
      "51:\tlearn: 1.5680909\ttotal: 22.9s\tremaining: 6m 58s\n",
      "52:\tlearn: 1.5670451\ttotal: 23.4s\tremaining: 6m 57s\n",
      "53:\tlearn: 1.5664332\ttotal: 23.8s\tremaining: 6m 56s\n",
      "54:\tlearn: 1.5652398\ttotal: 24.2s\tremaining: 6m 56s\n",
      "55:\tlearn: 1.5646831\ttotal: 24.7s\tremaining: 6m 55s\n",
      "56:\tlearn: 1.5640389\ttotal: 25.1s\tremaining: 6m 55s\n",
      "57:\tlearn: 1.5636038\ttotal: 25.5s\tremaining: 6m 54s\n",
      "58:\tlearn: 1.5629145\ttotal: 26s\tremaining: 6m 54s\n",
      "59:\tlearn: 1.5621134\ttotal: 26.4s\tremaining: 6m 53s\n",
      "60:\tlearn: 1.5603824\ttotal: 26.9s\tremaining: 6m 54s\n",
      "61:\tlearn: 1.5599268\ttotal: 27.4s\tremaining: 6m 55s\n",
      "62:\tlearn: 1.5593438\ttotal: 27.9s\tremaining: 6m 55s\n",
      "63:\tlearn: 1.5585946\ttotal: 28.4s\tremaining: 6m 55s\n",
      "64:\tlearn: 1.5580177\ttotal: 28.9s\tremaining: 6m 55s\n",
      "65:\tlearn: 1.5572783\ttotal: 29.4s\tremaining: 6m 55s\n",
      "66:\tlearn: 1.5565354\ttotal: 29.8s\tremaining: 6m 54s\n",
      "67:\tlearn: 1.5559877\ttotal: 30.3s\tremaining: 6m 54s\n",
      "68:\tlearn: 1.5552996\ttotal: 30.8s\tremaining: 6m 55s\n",
      "69:\tlearn: 1.5546046\ttotal: 31.2s\tremaining: 6m 54s\n",
      "70:\tlearn: 1.5540948\ttotal: 31.7s\tremaining: 6m 54s\n",
      "71:\tlearn: 1.5533931\ttotal: 32.2s\tremaining: 6m 55s\n",
      "72:\tlearn: 1.5529998\ttotal: 32.7s\tremaining: 6m 55s\n",
      "73:\tlearn: 1.5525078\ttotal: 33.2s\tremaining: 6m 55s\n",
      "74:\tlearn: 1.5521986\ttotal: 33.6s\tremaining: 6m 54s\n",
      "75:\tlearn: 1.5516622\ttotal: 34.1s\tremaining: 6m 54s\n",
      "76:\tlearn: 1.5512626\ttotal: 34.5s\tremaining: 6m 53s\n",
      "77:\tlearn: 1.5505893\ttotal: 34.9s\tremaining: 6m 52s\n",
      "78:\tlearn: 1.5501735\ttotal: 35.4s\tremaining: 6m 52s\n",
      "79:\tlearn: 1.5493233\ttotal: 35.8s\tremaining: 6m 51s\n",
      "80:\tlearn: 1.5489255\ttotal: 36.2s\tremaining: 6m 50s\n",
      "81:\tlearn: 1.5481924\ttotal: 36.7s\tremaining: 6m 50s\n",
      "82:\tlearn: 1.5477485\ttotal: 37.1s\tremaining: 6m 49s\n",
      "83:\tlearn: 1.5469203\ttotal: 37.5s\tremaining: 6m 49s\n",
      "84:\tlearn: 1.5463895\ttotal: 38s\tremaining: 6m 48s\n",
      "85:\tlearn: 1.5457940\ttotal: 38.4s\tremaining: 6m 47s\n",
      "86:\tlearn: 1.5451001\ttotal: 38.8s\tremaining: 6m 47s\n",
      "87:\tlearn: 1.5446387\ttotal: 39.2s\tremaining: 6m 46s\n",
      "88:\tlearn: 1.5443187\ttotal: 39.7s\tremaining: 6m 46s\n",
      "89:\tlearn: 1.5440043\ttotal: 40.1s\tremaining: 6m 45s\n",
      "90:\tlearn: 1.5434428\ttotal: 40.5s\tremaining: 6m 45s\n",
      "91:\tlearn: 1.5432230\ttotal: 41s\tremaining: 6m 44s\n",
      "92:\tlearn: 1.5428424\ttotal: 41.4s\tremaining: 6m 44s\n",
      "93:\tlearn: 1.5424946\ttotal: 41.9s\tremaining: 6m 43s\n",
      "94:\tlearn: 1.5417002\ttotal: 42.3s\tremaining: 6m 43s\n",
      "95:\tlearn: 1.5413473\ttotal: 42.7s\tremaining: 6m 42s\n",
      "96:\tlearn: 1.5410160\ttotal: 43.2s\tremaining: 6m 42s\n",
      "97:\tlearn: 1.5406886\ttotal: 43.6s\tremaining: 6m 41s\n",
      "98:\tlearn: 1.5402874\ttotal: 44s\tremaining: 6m 40s\n",
      "99:\tlearn: 1.5394658\ttotal: 44.5s\tremaining: 6m 40s\n",
      "100:\tlearn: 1.5389488\ttotal: 44.9s\tremaining: 6m 39s\n",
      "101:\tlearn: 1.5387021\ttotal: 45.3s\tremaining: 6m 39s\n",
      "102:\tlearn: 1.5383017\ttotal: 45.8s\tremaining: 6m 38s\n",
      "103:\tlearn: 1.5380269\ttotal: 46.2s\tremaining: 6m 38s\n",
      "104:\tlearn: 1.5377559\ttotal: 46.6s\tremaining: 6m 37s\n",
      "105:\tlearn: 1.5370305\ttotal: 47.1s\tremaining: 6m 36s\n",
      "106:\tlearn: 1.5363457\ttotal: 47.5s\tremaining: 6m 36s\n",
      "107:\tlearn: 1.5361228\ttotal: 47.9s\tremaining: 6m 35s\n",
      "108:\tlearn: 1.5353177\ttotal: 48.4s\tremaining: 6m 35s\n",
      "109:\tlearn: 1.5350596\ttotal: 48.8s\tremaining: 6m 34s\n",
      "110:\tlearn: 1.5346654\ttotal: 49.2s\tremaining: 6m 34s\n",
      "111:\tlearn: 1.5344060\ttotal: 49.7s\tremaining: 6m 33s\n",
      "112:\tlearn: 1.5340685\ttotal: 50.1s\tremaining: 6m 33s\n",
      "113:\tlearn: 1.5336033\ttotal: 50.5s\tremaining: 6m 32s\n",
      "114:\tlearn: 1.5331041\ttotal: 51s\tremaining: 6m 32s\n",
      "115:\tlearn: 1.5328140\ttotal: 51.4s\tremaining: 6m 31s\n",
      "116:\tlearn: 1.5326987\ttotal: 51.8s\tremaining: 6m 31s\n",
      "117:\tlearn: 1.5325332\ttotal: 52.3s\tremaining: 6m 30s\n",
      "118:\tlearn: 1.5321239\ttotal: 52.7s\tremaining: 6m 30s\n",
      "119:\tlearn: 1.5315873\ttotal: 53.1s\tremaining: 6m 29s\n",
      "120:\tlearn: 1.5313768\ttotal: 53.5s\tremaining: 6m 28s\n",
      "121:\tlearn: 1.5311215\ttotal: 54s\tremaining: 6m 28s\n",
      "122:\tlearn: 1.5300631\ttotal: 54.4s\tremaining: 6m 27s\n",
      "123:\tlearn: 1.5296248\ttotal: 54.8s\tremaining: 6m 27s\n",
      "124:\tlearn: 1.5291779\ttotal: 55.3s\tremaining: 6m 26s\n",
      "125:\tlearn: 1.5289163\ttotal: 55.7s\tremaining: 6m 26s\n",
      "126:\tlearn: 1.5282925\ttotal: 56.1s\tremaining: 6m 25s\n",
      "127:\tlearn: 1.5280103\ttotal: 56.6s\tremaining: 6m 25s\n",
      "128:\tlearn: 1.5274502\ttotal: 57s\tremaining: 6m 24s\n",
      "129:\tlearn: 1.5272215\ttotal: 57.4s\tremaining: 6m 24s\n",
      "130:\tlearn: 1.5267149\ttotal: 57.8s\tremaining: 6m 23s\n",
      "131:\tlearn: 1.5265413\ttotal: 58.3s\tremaining: 6m 23s\n",
      "132:\tlearn: 1.5261875\ttotal: 58.7s\tremaining: 6m 22s\n",
      "133:\tlearn: 1.5256487\ttotal: 59.1s\tremaining: 6m 22s\n",
      "134:\tlearn: 1.5253517\ttotal: 59.6s\tremaining: 6m 21s\n",
      "135:\tlearn: 1.5249383\ttotal: 1m\tremaining: 6m 21s\n",
      "136:\tlearn: 1.5246822\ttotal: 1m\tremaining: 6m 21s\n",
      "137:\tlearn: 1.5243938\ttotal: 1m\tremaining: 6m 20s\n",
      "138:\tlearn: 1.5242538\ttotal: 1m 1s\tremaining: 6m 20s\n",
      "139:\tlearn: 1.5240939\ttotal: 1m 1s\tremaining: 6m 19s\n",
      "140:\tlearn: 1.5239166\ttotal: 1m 2s\tremaining: 6m 19s\n",
      "141:\tlearn: 1.5236426\ttotal: 1m 2s\tremaining: 6m 19s\n",
      "142:\tlearn: 1.5230981\ttotal: 1m 3s\tremaining: 6m 18s\n",
      "143:\tlearn: 1.5225718\ttotal: 1m 3s\tremaining: 6m 18s\n",
      "144:\tlearn: 1.5223743\ttotal: 1m 4s\tremaining: 6m 17s\n",
      "145:\tlearn: 1.5219748\ttotal: 1m 4s\tremaining: 6m 17s\n",
      "146:\tlearn: 1.5218022\ttotal: 1m 4s\tremaining: 6m 16s\n",
      "147:\tlearn: 1.5214083\ttotal: 1m 5s\tremaining: 6m 16s\n",
      "148:\tlearn: 1.5211563\ttotal: 1m 5s\tremaining: 6m 15s\n",
      "149:\tlearn: 1.5209276\ttotal: 1m 6s\tremaining: 6m 15s\n",
      "150:\tlearn: 1.5206592\ttotal: 1m 6s\tremaining: 6m 15s\n",
      "151:\tlearn: 1.5203887\ttotal: 1m 7s\tremaining: 6m 15s\n",
      "152:\tlearn: 1.5198996\ttotal: 1m 7s\tremaining: 6m 14s\n",
      "153:\tlearn: 1.5195968\ttotal: 1m 8s\tremaining: 6m 14s\n",
      "154:\tlearn: 1.5189837\ttotal: 1m 8s\tremaining: 6m 13s\n",
      "155:\tlearn: 1.5188937\ttotal: 1m 9s\tremaining: 6m 13s\n",
      "156:\tlearn: 1.5185566\ttotal: 1m 9s\tremaining: 6m 12s\n",
      "157:\tlearn: 1.5183103\ttotal: 1m 9s\tremaining: 6m 12s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158:\tlearn: 1.5181569\ttotal: 1m 10s\tremaining: 6m 12s\n",
      "159:\tlearn: 1.5178579\ttotal: 1m 10s\tremaining: 6m 11s\n",
      "160:\tlearn: 1.5177560\ttotal: 1m 11s\tremaining: 6m 11s\n",
      "161:\tlearn: 1.5173265\ttotal: 1m 11s\tremaining: 6m 11s\n",
      "162:\tlearn: 1.5172207\ttotal: 1m 12s\tremaining: 6m 11s\n",
      "163:\tlearn: 1.5171332\ttotal: 1m 12s\tremaining: 6m 10s\n",
      "164:\tlearn: 1.5169593\ttotal: 1m 13s\tremaining: 6m 10s\n",
      "165:\tlearn: 1.5167312\ttotal: 1m 13s\tremaining: 6m 9s\n",
      "166:\tlearn: 1.5164692\ttotal: 1m 14s\tremaining: 6m 9s\n",
      "167:\tlearn: 1.5162749\ttotal: 1m 14s\tremaining: 6m 9s\n",
      "168:\tlearn: 1.5159206\ttotal: 1m 14s\tremaining: 6m 8s\n",
      "169:\tlearn: 1.5155835\ttotal: 1m 15s\tremaining: 6m 8s\n",
      "170:\tlearn: 1.5152785\ttotal: 1m 15s\tremaining: 6m 7s\n",
      "171:\tlearn: 1.5150983\ttotal: 1m 16s\tremaining: 6m 7s\n",
      "172:\tlearn: 1.5149162\ttotal: 1m 16s\tremaining: 6m 6s\n",
      "173:\tlearn: 1.5147530\ttotal: 1m 17s\tremaining: 6m 7s\n",
      "174:\tlearn: 1.5145146\ttotal: 1m 17s\tremaining: 6m 6s\n",
      "175:\tlearn: 1.5141987\ttotal: 1m 18s\tremaining: 6m 6s\n",
      "176:\tlearn: 1.5140624\ttotal: 1m 18s\tremaining: 6m 6s\n",
      "177:\tlearn: 1.5136091\ttotal: 1m 19s\tremaining: 6m 6s\n",
      "178:\tlearn: 1.5134887\ttotal: 1m 19s\tremaining: 6m 5s\n",
      "179:\tlearn: 1.5132783\ttotal: 1m 20s\tremaining: 6m 5s\n",
      "180:\tlearn: 1.5131290\ttotal: 1m 20s\tremaining: 6m 5s\n",
      "181:\tlearn: 1.5130119\ttotal: 1m 21s\tremaining: 6m 5s\n",
      "182:\tlearn: 1.5128322\ttotal: 1m 21s\tremaining: 6m 5s\n",
      "183:\tlearn: 1.5126128\ttotal: 1m 22s\tremaining: 6m 4s\n",
      "184:\tlearn: 1.5123911\ttotal: 1m 22s\tremaining: 6m 4s\n",
      "185:\tlearn: 1.5121903\ttotal: 1m 23s\tremaining: 6m 4s\n",
      "186:\tlearn: 1.5119890\ttotal: 1m 23s\tremaining: 6m 3s\n",
      "187:\tlearn: 1.5117560\ttotal: 1m 24s\tremaining: 6m 3s\n",
      "188:\tlearn: 1.5116565\ttotal: 1m 24s\tremaining: 6m 3s\n",
      "189:\tlearn: 1.5115858\ttotal: 1m 25s\tremaining: 6m 2s\n",
      "190:\tlearn: 1.5115084\ttotal: 1m 25s\tremaining: 6m 2s\n",
      "191:\tlearn: 1.5112441\ttotal: 1m 26s\tremaining: 6m 2s\n",
      "192:\tlearn: 1.5109215\ttotal: 1m 26s\tremaining: 6m 1s\n",
      "193:\tlearn: 1.5107117\ttotal: 1m 27s\tremaining: 6m 1s\n",
      "194:\tlearn: 1.5104421\ttotal: 1m 27s\tremaining: 6m 1s\n",
      "195:\tlearn: 1.5102329\ttotal: 1m 27s\tremaining: 6m\n",
      "196:\tlearn: 1.5099427\ttotal: 1m 28s\tremaining: 6m\n",
      "197:\tlearn: 1.5096895\ttotal: 1m 28s\tremaining: 5m 59s\n",
      "198:\tlearn: 1.5094096\ttotal: 1m 29s\tremaining: 5m 59s\n",
      "199:\tlearn: 1.5091649\ttotal: 1m 29s\tremaining: 5m 59s\n",
      "200:\tlearn: 1.5088819\ttotal: 1m 30s\tremaining: 5m 58s\n",
      "201:\tlearn: 1.5084844\ttotal: 1m 30s\tremaining: 5m 58s\n",
      "202:\tlearn: 1.5082694\ttotal: 1m 31s\tremaining: 5m 57s\n",
      "203:\tlearn: 1.5080768\ttotal: 1m 31s\tremaining: 5m 57s\n",
      "204:\tlearn: 1.5079094\ttotal: 1m 32s\tremaining: 5m 57s\n",
      "205:\tlearn: 1.5074833\ttotal: 1m 32s\tremaining: 5m 56s\n",
      "206:\tlearn: 1.5073240\ttotal: 1m 33s\tremaining: 5m 56s\n",
      "207:\tlearn: 1.5069758\ttotal: 1m 33s\tremaining: 5m 56s\n",
      "208:\tlearn: 1.5065448\ttotal: 1m 33s\tremaining: 5m 55s\n",
      "209:\tlearn: 1.5063853\ttotal: 1m 34s\tremaining: 5m 55s\n",
      "210:\tlearn: 1.5061847\ttotal: 1m 34s\tremaining: 5m 54s\n",
      "211:\tlearn: 1.5060346\ttotal: 1m 35s\tremaining: 5m 54s\n",
      "212:\tlearn: 1.5059565\ttotal: 1m 35s\tremaining: 5m 53s\n",
      "213:\tlearn: 1.5058322\ttotal: 1m 36s\tremaining: 5m 53s\n",
      "214:\tlearn: 1.5056844\ttotal: 1m 36s\tremaining: 5m 53s\n",
      "215:\tlearn: 1.5055444\ttotal: 1m 37s\tremaining: 5m 52s\n",
      "216:\tlearn: 1.5053891\ttotal: 1m 37s\tremaining: 5m 52s\n",
      "217:\tlearn: 1.5052503\ttotal: 1m 38s\tremaining: 5m 51s\n",
      "218:\tlearn: 1.5051857\ttotal: 1m 38s\tremaining: 5m 51s\n",
      "219:\tlearn: 1.5048895\ttotal: 1m 39s\tremaining: 5m 51s\n",
      "220:\tlearn: 1.5047945\ttotal: 1m 39s\tremaining: 5m 50s\n",
      "221:\tlearn: 1.5046732\ttotal: 1m 40s\tremaining: 5m 50s\n",
      "222:\tlearn: 1.5044802\ttotal: 1m 40s\tremaining: 5m 50s\n",
      "223:\tlearn: 1.5043024\ttotal: 1m 40s\tremaining: 5m 49s\n",
      "224:\tlearn: 1.5039681\ttotal: 1m 41s\tremaining: 5m 49s\n",
      "225:\tlearn: 1.5037830\ttotal: 1m 41s\tremaining: 5m 48s\n",
      "226:\tlearn: 1.5036013\ttotal: 1m 42s\tremaining: 5m 48s\n",
      "227:\tlearn: 1.5035216\ttotal: 1m 42s\tremaining: 5m 48s\n",
      "228:\tlearn: 1.5033905\ttotal: 1m 43s\tremaining: 5m 49s\n",
      "229:\tlearn: 1.5031666\ttotal: 1m 44s\tremaining: 5m 50s\n",
      "230:\tlearn: 1.5030086\ttotal: 1m 45s\tremaining: 5m 50s\n",
      "231:\tlearn: 1.5028892\ttotal: 1m 45s\tremaining: 5m 49s\n",
      "232:\tlearn: 1.5028175\ttotal: 1m 46s\tremaining: 5m 49s\n",
      "233:\tlearn: 1.5026555\ttotal: 1m 46s\tremaining: 5m 49s\n",
      "234:\tlearn: 1.5026101\ttotal: 1m 47s\tremaining: 5m 48s\n",
      "235:\tlearn: 1.5024898\ttotal: 1m 47s\tremaining: 5m 48s\n",
      "236:\tlearn: 1.5023495\ttotal: 1m 48s\tremaining: 5m 48s\n",
      "237:\tlearn: 1.5022287\ttotal: 1m 48s\tremaining: 5m 47s\n",
      "238:\tlearn: 1.5020587\ttotal: 1m 49s\tremaining: 5m 47s\n",
      "239:\tlearn: 1.5018714\ttotal: 1m 49s\tremaining: 5m 46s\n",
      "240:\tlearn: 1.5017115\ttotal: 1m 50s\tremaining: 5m 46s\n",
      "241:\tlearn: 1.5015073\ttotal: 1m 50s\tremaining: 5m 46s\n",
      "242:\tlearn: 1.5013297\ttotal: 1m 50s\tremaining: 5m 45s\n",
      "243:\tlearn: 1.5011951\ttotal: 1m 51s\tremaining: 5m 45s\n",
      "244:\tlearn: 1.5010886\ttotal: 1m 51s\tremaining: 5m 44s\n",
      "245:\tlearn: 1.5009864\ttotal: 1m 52s\tremaining: 5m 44s\n",
      "246:\tlearn: 1.5007492\ttotal: 1m 52s\tremaining: 5m 43s\n",
      "247:\tlearn: 1.5006402\ttotal: 1m 53s\tremaining: 5m 43s\n",
      "248:\tlearn: 1.5005942\ttotal: 1m 53s\tremaining: 5m 42s\n",
      "249:\tlearn: 1.5004440\ttotal: 1m 54s\tremaining: 5m 42s\n",
      "250:\tlearn: 1.5003230\ttotal: 1m 54s\tremaining: 5m 42s\n",
      "251:\tlearn: 1.5002245\ttotal: 1m 55s\tremaining: 5m 41s\n",
      "252:\tlearn: 1.4999358\ttotal: 1m 55s\tremaining: 5m 41s\n",
      "253:\tlearn: 1.4997283\ttotal: 1m 56s\tremaining: 5m 41s\n",
      "254:\tlearn: 1.4995823\ttotal: 1m 56s\tremaining: 5m 41s\n",
      "255:\tlearn: 1.4993929\ttotal: 1m 57s\tremaining: 5m 40s\n",
      "256:\tlearn: 1.4992482\ttotal: 1m 57s\tremaining: 5m 40s\n",
      "257:\tlearn: 1.4991160\ttotal: 1m 58s\tremaining: 5m 40s\n",
      "258:\tlearn: 1.4989301\ttotal: 1m 58s\tremaining: 5m 39s\n",
      "259:\tlearn: 1.4986312\ttotal: 1m 59s\tremaining: 5m 39s\n",
      "260:\tlearn: 1.4984954\ttotal: 1m 59s\tremaining: 5m 38s\n",
      "261:\tlearn: 1.4983194\ttotal: 2m\tremaining: 5m 38s\n",
      "262:\tlearn: 1.4982244\ttotal: 2m\tremaining: 5m 37s\n",
      "263:\tlearn: 1.4979979\ttotal: 2m\tremaining: 5m 37s\n",
      "264:\tlearn: 1.4979094\ttotal: 2m 1s\tremaining: 5m 36s\n",
      "265:\tlearn: 1.4977540\ttotal: 2m 1s\tremaining: 5m 36s\n",
      "266:\tlearn: 1.4976002\ttotal: 2m 2s\tremaining: 5m 35s\n",
      "267:\tlearn: 1.4974969\ttotal: 2m 2s\tremaining: 5m 35s\n",
      "268:\tlearn: 1.4973725\ttotal: 2m 3s\tremaining: 5m 35s\n",
      "269:\tlearn: 1.4971815\ttotal: 2m 3s\tremaining: 5m 34s\n",
      "270:\tlearn: 1.4970402\ttotal: 2m 4s\tremaining: 5m 34s\n",
      "271:\tlearn: 1.4970062\ttotal: 2m 4s\tremaining: 5m 33s\n",
      "272:\tlearn: 1.4969179\ttotal: 2m 5s\tremaining: 5m 33s\n",
      "273:\tlearn: 1.4967773\ttotal: 2m 5s\tremaining: 5m 32s\n",
      "274:\tlearn: 1.4965948\ttotal: 2m 6s\tremaining: 5m 32s\n",
      "275:\tlearn: 1.4964207\ttotal: 2m 6s\tremaining: 5m 32s\n",
      "276:\tlearn: 1.4963205\ttotal: 2m 7s\tremaining: 5m 32s\n",
      "277:\tlearn: 1.4962635\ttotal: 2m 7s\tremaining: 5m 32s\n",
      "278:\tlearn: 1.4962250\ttotal: 2m 8s\tremaining: 5m 32s\n",
      "279:\tlearn: 1.4960843\ttotal: 2m 9s\tremaining: 5m 32s\n",
      "280:\tlearn: 1.4958982\ttotal: 2m 9s\tremaining: 5m 31s\n",
      "281:\tlearn: 1.4957950\ttotal: 2m 10s\tremaining: 5m 31s\n",
      "282:\tlearn: 1.4956818\ttotal: 2m 10s\tremaining: 5m 31s\n",
      "283:\tlearn: 1.4955804\ttotal: 2m 11s\tremaining: 5m 30s\n",
      "284:\tlearn: 1.4953757\ttotal: 2m 11s\tremaining: 5m 30s\n",
      "285:\tlearn: 1.4951947\ttotal: 2m 12s\tremaining: 5m 29s\n",
      "286:\tlearn: 1.4951167\ttotal: 2m 12s\tremaining: 5m 29s\n",
      "287:\tlearn: 1.4948846\ttotal: 2m 13s\tremaining: 5m 28s\n",
      "288:\tlearn: 1.4946868\ttotal: 2m 13s\tremaining: 5m 28s\n",
      "289:\tlearn: 1.4945500\ttotal: 2m 13s\tremaining: 5m 28s\n",
      "290:\tlearn: 1.4944521\ttotal: 2m 14s\tremaining: 5m 27s\n",
      "291:\tlearn: 1.4943361\ttotal: 2m 14s\tremaining: 5m 27s\n",
      "292:\tlearn: 1.4942534\ttotal: 2m 15s\tremaining: 5m 26s\n",
      "293:\tlearn: 1.4941188\ttotal: 2m 15s\tremaining: 5m 26s\n",
      "294:\tlearn: 1.4940205\ttotal: 2m 16s\tremaining: 5m 25s\n",
      "295:\tlearn: 1.4938988\ttotal: 2m 16s\tremaining: 5m 24s\n",
      "296:\tlearn: 1.4938119\ttotal: 2m 17s\tremaining: 5m 24s\n",
      "297:\tlearn: 1.4937926\ttotal: 2m 17s\tremaining: 5m 23s\n",
      "298:\tlearn: 1.4936720\ttotal: 2m 17s\tremaining: 5m 23s\n",
      "299:\tlearn: 1.4934962\ttotal: 2m 18s\tremaining: 5m 22s\n",
      "300:\tlearn: 1.4933243\ttotal: 2m 18s\tremaining: 5m 22s\n",
      "301:\tlearn: 1.4931518\ttotal: 2m 19s\tremaining: 5m 21s\n",
      "302:\tlearn: 1.4930054\ttotal: 2m 19s\tremaining: 5m 21s\n",
      "303:\tlearn: 1.4928609\ttotal: 2m 20s\tremaining: 5m 20s\n",
      "304:\tlearn: 1.4927894\ttotal: 2m 20s\tremaining: 5m 20s\n",
      "305:\tlearn: 1.4925276\ttotal: 2m 21s\tremaining: 5m 19s\n",
      "306:\tlearn: 1.4924333\ttotal: 2m 21s\tremaining: 5m 19s\n",
      "307:\tlearn: 1.4923511\ttotal: 2m 21s\tremaining: 5m 18s\n",
      "308:\tlearn: 1.4922628\ttotal: 2m 22s\tremaining: 5m 18s\n",
      "309:\tlearn: 1.4921721\ttotal: 2m 22s\tremaining: 5m 17s\n",
      "310:\tlearn: 1.4921170\ttotal: 2m 23s\tremaining: 5m 17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311:\tlearn: 1.4919904\ttotal: 2m 23s\tremaining: 5m 16s\n",
      "312:\tlearn: 1.4919136\ttotal: 2m 24s\tremaining: 5m 16s\n",
      "313:\tlearn: 1.4918421\ttotal: 2m 24s\tremaining: 5m 15s\n",
      "314:\tlearn: 1.4916662\ttotal: 2m 24s\tremaining: 5m 15s\n",
      "315:\tlearn: 1.4914783\ttotal: 2m 25s\tremaining: 5m 14s\n",
      "316:\tlearn: 1.4912938\ttotal: 2m 25s\tremaining: 5m 14s\n",
      "317:\tlearn: 1.4911732\ttotal: 2m 26s\tremaining: 5m 13s\n",
      "318:\tlearn: 1.4910255\ttotal: 2m 26s\tremaining: 5m 13s\n",
      "319:\tlearn: 1.4908848\ttotal: 2m 27s\tremaining: 5m 12s\n",
      "320:\tlearn: 1.4906590\ttotal: 2m 27s\tremaining: 5m 12s\n",
      "321:\tlearn: 1.4905936\ttotal: 2m 28s\tremaining: 5m 11s\n",
      "322:\tlearn: 1.4904137\ttotal: 2m 28s\tremaining: 5m 11s\n",
      "323:\tlearn: 1.4902692\ttotal: 2m 28s\tremaining: 5m 10s\n",
      "324:\tlearn: 1.4901259\ttotal: 2m 29s\tremaining: 5m 10s\n",
      "325:\tlearn: 1.4900140\ttotal: 2m 29s\tremaining: 5m 9s\n",
      "326:\tlearn: 1.4899148\ttotal: 2m 30s\tremaining: 5m 9s\n",
      "327:\tlearn: 1.4898123\ttotal: 2m 30s\tremaining: 5m 8s\n",
      "328:\tlearn: 1.4896479\ttotal: 2m 31s\tremaining: 5m 8s\n",
      "329:\tlearn: 1.4894948\ttotal: 2m 31s\tremaining: 5m 7s\n",
      "330:\tlearn: 1.4893769\ttotal: 2m 32s\tremaining: 5m 7s\n",
      "331:\tlearn: 1.4892070\ttotal: 2m 32s\tremaining: 5m 6s\n",
      "332:\tlearn: 1.4890206\ttotal: 2m 33s\tremaining: 5m 6s\n",
      "333:\tlearn: 1.4888969\ttotal: 2m 33s\tremaining: 5m 6s\n",
      "334:\tlearn: 1.4888394\ttotal: 2m 34s\tremaining: 5m 5s\n",
      "335:\tlearn: 1.4887509\ttotal: 2m 34s\tremaining: 5m 5s\n",
      "336:\tlearn: 1.4886576\ttotal: 2m 34s\tremaining: 5m 4s\n",
      "337:\tlearn: 1.4885590\ttotal: 2m 35s\tremaining: 5m 4s\n",
      "338:\tlearn: 1.4884923\ttotal: 2m 35s\tremaining: 5m 3s\n",
      "339:\tlearn: 1.4882847\ttotal: 2m 36s\tremaining: 5m 3s\n",
      "340:\tlearn: 1.4881660\ttotal: 2m 36s\tremaining: 5m 2s\n",
      "341:\tlearn: 1.4879896\ttotal: 2m 37s\tremaining: 5m 2s\n",
      "342:\tlearn: 1.4879442\ttotal: 2m 37s\tremaining: 5m 1s\n",
      "343:\tlearn: 1.4879121\ttotal: 2m 37s\tremaining: 5m 1s\n",
      "344:\tlearn: 1.4877176\ttotal: 2m 38s\tremaining: 5m\n",
      "345:\tlearn: 1.4875334\ttotal: 2m 38s\tremaining: 5m\n",
      "346:\tlearn: 1.4874805\ttotal: 2m 39s\tremaining: 4m 59s\n",
      "347:\tlearn: 1.4874097\ttotal: 2m 39s\tremaining: 4m 59s\n",
      "348:\tlearn: 1.4872645\ttotal: 2m 40s\tremaining: 4m 58s\n",
      "349:\tlearn: 1.4872191\ttotal: 2m 40s\tremaining: 4m 58s\n",
      "350:\tlearn: 1.4871534\ttotal: 2m 40s\tremaining: 4m 57s\n",
      "351:\tlearn: 1.4871114\ttotal: 2m 41s\tremaining: 4m 57s\n",
      "352:\tlearn: 1.4869746\ttotal: 2m 41s\tremaining: 4m 56s\n",
      "353:\tlearn: 1.4868181\ttotal: 2m 42s\tremaining: 4m 56s\n",
      "354:\tlearn: 1.4866923\ttotal: 2m 42s\tremaining: 4m 55s\n",
      "355:\tlearn: 1.4865515\ttotal: 2m 43s\tremaining: 4m 55s\n",
      "356:\tlearn: 1.4864589\ttotal: 2m 43s\tremaining: 4m 54s\n",
      "357:\tlearn: 1.4863293\ttotal: 2m 43s\tremaining: 4m 54s\n",
      "358:\tlearn: 1.4862238\ttotal: 2m 44s\tremaining: 4m 53s\n",
      "359:\tlearn: 1.4860898\ttotal: 2m 44s\tremaining: 4m 53s\n",
      "360:\tlearn: 1.4859167\ttotal: 2m 45s\tremaining: 4m 52s\n",
      "361:\tlearn: 1.4858392\ttotal: 2m 45s\tremaining: 4m 52s\n",
      "362:\tlearn: 1.4856950\ttotal: 2m 46s\tremaining: 4m 51s\n",
      "363:\tlearn: 1.4855482\ttotal: 2m 46s\tremaining: 4m 51s\n",
      "364:\tlearn: 1.4854329\ttotal: 2m 47s\tremaining: 4m 50s\n",
      "365:\tlearn: 1.4853529\ttotal: 2m 47s\tremaining: 4m 50s\n",
      "366:\tlearn: 1.4852506\ttotal: 2m 47s\tremaining: 4m 49s\n",
      "367:\tlearn: 1.4850987\ttotal: 2m 48s\tremaining: 4m 49s\n",
      "368:\tlearn: 1.4850012\ttotal: 2m 48s\tremaining: 4m 48s\n",
      "369:\tlearn: 1.4849195\ttotal: 2m 49s\tremaining: 4m 48s\n",
      "370:\tlearn: 1.4848238\ttotal: 2m 49s\tremaining: 4m 47s\n",
      "371:\tlearn: 1.4847297\ttotal: 2m 50s\tremaining: 4m 47s\n",
      "372:\tlearn: 1.4846951\ttotal: 2m 50s\tremaining: 4m 46s\n",
      "373:\tlearn: 1.4845890\ttotal: 2m 51s\tremaining: 4m 46s\n",
      "374:\tlearn: 1.4844408\ttotal: 2m 51s\tremaining: 4m 45s\n",
      "375:\tlearn: 1.4843382\ttotal: 2m 51s\tremaining: 4m 45s\n",
      "376:\tlearn: 1.4842788\ttotal: 2m 52s\tremaining: 4m 44s\n",
      "377:\tlearn: 1.4841483\ttotal: 2m 52s\tremaining: 4m 44s\n",
      "378:\tlearn: 1.4840860\ttotal: 2m 53s\tremaining: 4m 44s\n",
      "379:\tlearn: 1.4839316\ttotal: 2m 53s\tremaining: 4m 43s\n",
      "380:\tlearn: 1.4838559\ttotal: 2m 54s\tremaining: 4m 43s\n",
      "381:\tlearn: 1.4837724\ttotal: 2m 54s\tremaining: 4m 42s\n",
      "382:\tlearn: 1.4836878\ttotal: 2m 55s\tremaining: 4m 42s\n",
      "383:\tlearn: 1.4835561\ttotal: 2m 55s\tremaining: 4m 41s\n",
      "384:\tlearn: 1.4834891\ttotal: 2m 55s\tremaining: 4m 41s\n",
      "385:\tlearn: 1.4832713\ttotal: 2m 56s\tremaining: 4m 40s\n",
      "386:\tlearn: 1.4831849\ttotal: 2m 56s\tremaining: 4m 40s\n",
      "387:\tlearn: 1.4830383\ttotal: 2m 57s\tremaining: 4m 39s\n",
      "388:\tlearn: 1.4828807\ttotal: 2m 57s\tremaining: 4m 39s\n",
      "389:\tlearn: 1.4828481\ttotal: 2m 58s\tremaining: 4m 38s\n",
      "390:\tlearn: 1.4827259\ttotal: 2m 58s\tremaining: 4m 38s\n",
      "391:\tlearn: 1.4826157\ttotal: 2m 59s\tremaining: 4m 37s\n",
      "392:\tlearn: 1.4825010\ttotal: 2m 59s\tremaining: 4m 37s\n",
      "393:\tlearn: 1.4823714\ttotal: 3m\tremaining: 4m 36s\n",
      "394:\tlearn: 1.4822822\ttotal: 3m\tremaining: 4m 36s\n",
      "395:\tlearn: 1.4821986\ttotal: 3m\tremaining: 4m 35s\n",
      "396:\tlearn: 1.4820451\ttotal: 3m 1s\tremaining: 4m 35s\n",
      "397:\tlearn: 1.4819321\ttotal: 3m 1s\tremaining: 4m 35s\n",
      "398:\tlearn: 1.4818356\ttotal: 3m 2s\tremaining: 4m 34s\n",
      "399:\tlearn: 1.4817430\ttotal: 3m 2s\tremaining: 4m 34s\n",
      "400:\tlearn: 1.4816541\ttotal: 3m 3s\tremaining: 4m 33s\n",
      "401:\tlearn: 1.4816182\ttotal: 3m 3s\tremaining: 4m 33s\n",
      "402:\tlearn: 1.4814576\ttotal: 3m 4s\tremaining: 4m 32s\n",
      "403:\tlearn: 1.4813568\ttotal: 3m 4s\tremaining: 4m 32s\n",
      "404:\tlearn: 1.4812300\ttotal: 3m 4s\tremaining: 4m 31s\n",
      "405:\tlearn: 1.4810989\ttotal: 3m 5s\tremaining: 4m 31s\n",
      "406:\tlearn: 1.4810030\ttotal: 3m 5s\tremaining: 4m 30s\n",
      "407:\tlearn: 1.4808101\ttotal: 3m 6s\tremaining: 4m 30s\n",
      "408:\tlearn: 1.4807410\ttotal: 3m 6s\tremaining: 4m 29s\n",
      "409:\tlearn: 1.4806535\ttotal: 3m 7s\tremaining: 4m 29s\n",
      "410:\tlearn: 1.4805582\ttotal: 3m 7s\tremaining: 4m 28s\n",
      "411:\tlearn: 1.4805306\ttotal: 3m 8s\tremaining: 4m 28s\n",
      "412:\tlearn: 1.4803898\ttotal: 3m 8s\tremaining: 4m 28s\n",
      "413:\tlearn: 1.4803529\ttotal: 3m 9s\tremaining: 4m 27s\n",
      "414:\tlearn: 1.4802132\ttotal: 3m 9s\tremaining: 4m 27s\n",
      "415:\tlearn: 1.4801077\ttotal: 3m 10s\tremaining: 4m 26s\n",
      "416:\tlearn: 1.4800418\ttotal: 3m 10s\tremaining: 4m 26s\n",
      "417:\tlearn: 1.4799101\ttotal: 3m 10s\tremaining: 4m 25s\n",
      "418:\tlearn: 1.4798157\ttotal: 3m 11s\tremaining: 4m 25s\n",
      "419:\tlearn: 1.4795984\ttotal: 3m 12s\tremaining: 4m 25s\n",
      "420:\tlearn: 1.4794160\ttotal: 3m 12s\tremaining: 4m 24s\n",
      "421:\tlearn: 1.4792402\ttotal: 3m 12s\tremaining: 4m 24s\n",
      "422:\tlearn: 1.4791501\ttotal: 3m 13s\tremaining: 4m 23s\n",
      "423:\tlearn: 1.4790959\ttotal: 3m 13s\tremaining: 4m 23s\n",
      "424:\tlearn: 1.4790026\ttotal: 3m 14s\tremaining: 4m 22s\n",
      "425:\tlearn: 1.4788940\ttotal: 3m 14s\tremaining: 4m 22s\n",
      "426:\tlearn: 1.4787294\ttotal: 3m 15s\tremaining: 4m 22s\n",
      "427:\tlearn: 1.4786167\ttotal: 3m 15s\tremaining: 4m 21s\n",
      "428:\tlearn: 1.4785194\ttotal: 3m 16s\tremaining: 4m 21s\n",
      "429:\tlearn: 1.4783848\ttotal: 3m 16s\tremaining: 4m 20s\n",
      "430:\tlearn: 1.4783047\ttotal: 3m 17s\tremaining: 4m 20s\n",
      "431:\tlearn: 1.4782126\ttotal: 3m 17s\tremaining: 4m 19s\n",
      "432:\tlearn: 1.4780509\ttotal: 3m 18s\tremaining: 4m 19s\n",
      "433:\tlearn: 1.4779204\ttotal: 3m 18s\tremaining: 4m 18s\n",
      "434:\tlearn: 1.4778280\ttotal: 3m 18s\tremaining: 4m 18s\n",
      "435:\tlearn: 1.4777405\ttotal: 3m 19s\tremaining: 4m 17s\n",
      "436:\tlearn: 1.4776188\ttotal: 3m 19s\tremaining: 4m 17s\n",
      "437:\tlearn: 1.4774694\ttotal: 3m 20s\tremaining: 4m 16s\n",
      "438:\tlearn: 1.4773324\ttotal: 3m 20s\tremaining: 4m 16s\n",
      "439:\tlearn: 1.4772888\ttotal: 3m 21s\tremaining: 4m 15s\n",
      "440:\tlearn: 1.4772000\ttotal: 3m 21s\tremaining: 4m 15s\n",
      "441:\tlearn: 1.4771141\ttotal: 3m 22s\tremaining: 4m 15s\n",
      "442:\tlearn: 1.4770265\ttotal: 3m 22s\tremaining: 4m 14s\n",
      "443:\tlearn: 1.4768755\ttotal: 3m 22s\tremaining: 4m 14s\n",
      "444:\tlearn: 1.4767789\ttotal: 3m 23s\tremaining: 4m 13s\n",
      "445:\tlearn: 1.4766338\ttotal: 3m 23s\tremaining: 4m 13s\n",
      "446:\tlearn: 1.4765147\ttotal: 3m 24s\tremaining: 4m 12s\n",
      "447:\tlearn: 1.4764006\ttotal: 3m 24s\tremaining: 4m 12s\n",
      "448:\tlearn: 1.4763114\ttotal: 3m 25s\tremaining: 4m 11s\n",
      "449:\tlearn: 1.4761784\ttotal: 3m 25s\tremaining: 4m 11s\n",
      "450:\tlearn: 1.4761401\ttotal: 3m 26s\tremaining: 4m 10s\n",
      "451:\tlearn: 1.4759966\ttotal: 3m 26s\tremaining: 4m 10s\n",
      "452:\tlearn: 1.4759324\ttotal: 3m 27s\tremaining: 4m 10s\n",
      "453:\tlearn: 1.4758630\ttotal: 3m 27s\tremaining: 4m 9s\n",
      "454:\tlearn: 1.4757781\ttotal: 3m 28s\tremaining: 4m 9s\n",
      "455:\tlearn: 1.4756621\ttotal: 3m 28s\tremaining: 4m 8s\n",
      "456:\tlearn: 1.4755619\ttotal: 3m 28s\tremaining: 4m 8s\n",
      "457:\tlearn: 1.4755433\ttotal: 3m 29s\tremaining: 4m 8s\n",
      "458:\tlearn: 1.4754819\ttotal: 3m 30s\tremaining: 4m 7s\n",
      "459:\tlearn: 1.4754128\ttotal: 3m 30s\tremaining: 4m 7s\n",
      "460:\tlearn: 1.4753037\ttotal: 3m 31s\tremaining: 4m 6s\n",
      "461:\tlearn: 1.4752403\ttotal: 3m 31s\tremaining: 4m 6s\n",
      "462:\tlearn: 1.4750521\ttotal: 3m 32s\tremaining: 4m 5s\n",
      "463:\tlearn: 1.4749696\ttotal: 3m 32s\tremaining: 4m 5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464:\tlearn: 1.4748915\ttotal: 3m 33s\tremaining: 4m 5s\n",
      "465:\tlearn: 1.4747896\ttotal: 3m 33s\tremaining: 4m 4s\n",
      "466:\tlearn: 1.4747061\ttotal: 3m 33s\tremaining: 4m 4s\n",
      "467:\tlearn: 1.4746520\ttotal: 3m 34s\tremaining: 4m 3s\n",
      "468:\tlearn: 1.4745618\ttotal: 3m 34s\tremaining: 4m 3s\n",
      "469:\tlearn: 1.4744409\ttotal: 3m 35s\tremaining: 4m 2s\n",
      "470:\tlearn: 1.4743745\ttotal: 3m 35s\tremaining: 4m 2s\n",
      "471:\tlearn: 1.4742605\ttotal: 3m 36s\tremaining: 4m 2s\n",
      "472:\tlearn: 1.4741306\ttotal: 3m 36s\tremaining: 4m 1s\n",
      "473:\tlearn: 1.4740534\ttotal: 3m 37s\tremaining: 4m 1s\n",
      "474:\tlearn: 1.4740015\ttotal: 3m 37s\tremaining: 4m\n",
      "475:\tlearn: 1.4739225\ttotal: 3m 38s\tremaining: 4m\n",
      "476:\tlearn: 1.4736968\ttotal: 3m 38s\tremaining: 3m 59s\n",
      "477:\tlearn: 1.4735971\ttotal: 3m 39s\tremaining: 3m 59s\n",
      "478:\tlearn: 1.4735095\ttotal: 3m 39s\tremaining: 3m 58s\n",
      "479:\tlearn: 1.4733978\ttotal: 3m 39s\tremaining: 3m 58s\n",
      "480:\tlearn: 1.4732883\ttotal: 3m 40s\tremaining: 3m 57s\n",
      "481:\tlearn: 1.4731884\ttotal: 3m 40s\tremaining: 3m 57s\n",
      "482:\tlearn: 1.4729818\ttotal: 3m 41s\tremaining: 3m 56s\n",
      "483:\tlearn: 1.4729094\ttotal: 3m 41s\tremaining: 3m 56s\n",
      "484:\tlearn: 1.4728238\ttotal: 3m 41s\tremaining: 3m 55s\n",
      "485:\tlearn: 1.4726944\ttotal: 3m 42s\tremaining: 3m 55s\n",
      "486:\tlearn: 1.4726156\ttotal: 3m 42s\tremaining: 3m 54s\n",
      "487:\tlearn: 1.4725658\ttotal: 3m 43s\tremaining: 3m 54s\n",
      "488:\tlearn: 1.4725074\ttotal: 3m 43s\tremaining: 3m 53s\n",
      "489:\tlearn: 1.4723968\ttotal: 3m 44s\tremaining: 3m 53s\n",
      "490:\tlearn: 1.4723743\ttotal: 3m 44s\tremaining: 3m 52s\n",
      "491:\tlearn: 1.4722768\ttotal: 3m 45s\tremaining: 3m 52s\n",
      "492:\tlearn: 1.4722281\ttotal: 3m 45s\tremaining: 3m 51s\n",
      "493:\tlearn: 1.4721107\ttotal: 3m 45s\tremaining: 3m 51s\n",
      "494:\tlearn: 1.4720754\ttotal: 3m 46s\tremaining: 3m 50s\n",
      "495:\tlearn: 1.4719916\ttotal: 3m 46s\tremaining: 3m 50s\n",
      "496:\tlearn: 1.4718976\ttotal: 3m 47s\tremaining: 3m 49s\n",
      "497:\tlearn: 1.4718478\ttotal: 3m 47s\tremaining: 3m 49s\n",
      "498:\tlearn: 1.4717447\ttotal: 3m 48s\tremaining: 3m 48s\n",
      "499:\tlearn: 1.4715891\ttotal: 3m 48s\tremaining: 3m 48s\n",
      "500:\tlearn: 1.4714875\ttotal: 3m 48s\tremaining: 3m 47s\n",
      "501:\tlearn: 1.4713825\ttotal: 3m 49s\tremaining: 3m 47s\n",
      "502:\tlearn: 1.4712990\ttotal: 3m 49s\tremaining: 3m 47s\n",
      "503:\tlearn: 1.4712220\ttotal: 3m 50s\tremaining: 3m 46s\n",
      "504:\tlearn: 1.4711916\ttotal: 3m 50s\tremaining: 3m 46s\n",
      "505:\tlearn: 1.4711588\ttotal: 3m 51s\tremaining: 3m 45s\n",
      "506:\tlearn: 1.4710422\ttotal: 3m 51s\tremaining: 3m 45s\n",
      "507:\tlearn: 1.4709092\ttotal: 3m 51s\tremaining: 3m 44s\n",
      "508:\tlearn: 1.4707919\ttotal: 3m 52s\tremaining: 3m 44s\n",
      "509:\tlearn: 1.4707088\ttotal: 3m 52s\tremaining: 3m 43s\n",
      "510:\tlearn: 1.4706662\ttotal: 3m 53s\tremaining: 3m 43s\n",
      "511:\tlearn: 1.4705761\ttotal: 3m 53s\tremaining: 3m 42s\n",
      "512:\tlearn: 1.4704359\ttotal: 3m 54s\tremaining: 3m 42s\n",
      "513:\tlearn: 1.4702600\ttotal: 3m 54s\tremaining: 3m 41s\n",
      "514:\tlearn: 1.4701573\ttotal: 3m 55s\tremaining: 3m 41s\n",
      "515:\tlearn: 1.4701262\ttotal: 3m 55s\tremaining: 3m 40s\n",
      "516:\tlearn: 1.4700624\ttotal: 3m 55s\tremaining: 3m 40s\n",
      "517:\tlearn: 1.4699314\ttotal: 3m 56s\tremaining: 3m 39s\n",
      "518:\tlearn: 1.4698306\ttotal: 3m 56s\tremaining: 3m 39s\n",
      "519:\tlearn: 1.4697583\ttotal: 3m 57s\tremaining: 3m 38s\n",
      "520:\tlearn: 1.4696356\ttotal: 3m 57s\tremaining: 3m 38s\n",
      "521:\tlearn: 1.4694726\ttotal: 3m 58s\tremaining: 3m 37s\n",
      "522:\tlearn: 1.4694399\ttotal: 3m 58s\tremaining: 3m 37s\n",
      "523:\tlearn: 1.4693956\ttotal: 3m 58s\tremaining: 3m 37s\n",
      "524:\tlearn: 1.4693216\ttotal: 3m 59s\tremaining: 3m 36s\n",
      "525:\tlearn: 1.4692048\ttotal: 3m 59s\tremaining: 3m 36s\n",
      "526:\tlearn: 1.4691322\ttotal: 4m\tremaining: 3m 35s\n",
      "527:\tlearn: 1.4690282\ttotal: 4m\tremaining: 3m 35s\n",
      "528:\tlearn: 1.4689714\ttotal: 4m 1s\tremaining: 3m 34s\n",
      "529:\tlearn: 1.4688901\ttotal: 4m 1s\tremaining: 3m 34s\n",
      "530:\tlearn: 1.4687807\ttotal: 4m 1s\tremaining: 3m 33s\n",
      "531:\tlearn: 1.4687458\ttotal: 4m 2s\tremaining: 3m 33s\n",
      "532:\tlearn: 1.4686486\ttotal: 4m 2s\tremaining: 3m 32s\n",
      "533:\tlearn: 1.4685886\ttotal: 4m 3s\tremaining: 3m 32s\n",
      "534:\tlearn: 1.4684916\ttotal: 4m 3s\tremaining: 3m 31s\n",
      "535:\tlearn: 1.4683937\ttotal: 4m 4s\tremaining: 3m 31s\n",
      "536:\tlearn: 1.4683241\ttotal: 4m 4s\tremaining: 3m 30s\n",
      "537:\tlearn: 1.4681862\ttotal: 4m 4s\tremaining: 3m 30s\n",
      "538:\tlearn: 1.4681344\ttotal: 4m 5s\tremaining: 3m 29s\n",
      "539:\tlearn: 1.4680635\ttotal: 4m 5s\tremaining: 3m 29s\n",
      "540:\tlearn: 1.4679906\ttotal: 4m 6s\tremaining: 3m 28s\n",
      "541:\tlearn: 1.4679050\ttotal: 4m 6s\tremaining: 3m 28s\n",
      "542:\tlearn: 1.4678047\ttotal: 4m 7s\tremaining: 3m 27s\n",
      "543:\tlearn: 1.4677168\ttotal: 4m 7s\tremaining: 3m 27s\n",
      "544:\tlearn: 1.4676559\ttotal: 4m 7s\tremaining: 3m 26s\n",
      "545:\tlearn: 1.4675960\ttotal: 4m 8s\tremaining: 3m 26s\n",
      "546:\tlearn: 1.4675088\ttotal: 4m 8s\tremaining: 3m 26s\n",
      "547:\tlearn: 1.4673773\ttotal: 4m 9s\tremaining: 3m 25s\n",
      "548:\tlearn: 1.4673294\ttotal: 4m 9s\tremaining: 3m 25s\n",
      "549:\tlearn: 1.4672366\ttotal: 4m 10s\tremaining: 3m 24s\n",
      "550:\tlearn: 1.4670026\ttotal: 4m 10s\tremaining: 3m 24s\n",
      "551:\tlearn: 1.4669205\ttotal: 4m 10s\tremaining: 3m 23s\n",
      "552:\tlearn: 1.4667882\ttotal: 4m 11s\tremaining: 3m 23s\n",
      "553:\tlearn: 1.4667173\ttotal: 4m 11s\tremaining: 3m 22s\n",
      "554:\tlearn: 1.4666155\ttotal: 4m 12s\tremaining: 3m 22s\n",
      "555:\tlearn: 1.4665228\ttotal: 4m 12s\tremaining: 3m 21s\n",
      "556:\tlearn: 1.4665005\ttotal: 4m 13s\tremaining: 3m 21s\n",
      "557:\tlearn: 1.4664134\ttotal: 4m 13s\tremaining: 3m 20s\n",
      "558:\tlearn: 1.4663685\ttotal: 4m 13s\tremaining: 3m 20s\n",
      "559:\tlearn: 1.4662742\ttotal: 4m 14s\tremaining: 3m 19s\n",
      "560:\tlearn: 1.4661930\ttotal: 4m 14s\tremaining: 3m 19s\n",
      "561:\tlearn: 1.4660631\ttotal: 4m 15s\tremaining: 3m 18s\n",
      "562:\tlearn: 1.4659901\ttotal: 4m 15s\tremaining: 3m 18s\n",
      "563:\tlearn: 1.4658911\ttotal: 4m 16s\tremaining: 3m 18s\n",
      "564:\tlearn: 1.4658128\ttotal: 4m 16s\tremaining: 3m 17s\n",
      "565:\tlearn: 1.4657585\ttotal: 4m 17s\tremaining: 3m 17s\n",
      "566:\tlearn: 1.4656999\ttotal: 4m 17s\tremaining: 3m 16s\n",
      "567:\tlearn: 1.4655902\ttotal: 4m 17s\tremaining: 3m 16s\n",
      "568:\tlearn: 1.4655443\ttotal: 4m 18s\tremaining: 3m 15s\n",
      "569:\tlearn: 1.4654763\ttotal: 4m 18s\tremaining: 3m 15s\n",
      "570:\tlearn: 1.4654183\ttotal: 4m 19s\tremaining: 3m 14s\n",
      "571:\tlearn: 1.4653160\ttotal: 4m 19s\tremaining: 3m 14s\n",
      "572:\tlearn: 1.4651607\ttotal: 4m 20s\tremaining: 3m 13s\n",
      "573:\tlearn: 1.4650903\ttotal: 4m 20s\tremaining: 3m 13s\n",
      "574:\tlearn: 1.4650435\ttotal: 4m 20s\tremaining: 3m 12s\n",
      "575:\tlearn: 1.4649480\ttotal: 4m 21s\tremaining: 3m 12s\n",
      "576:\tlearn: 1.4648970\ttotal: 4m 21s\tremaining: 3m 11s\n",
      "577:\tlearn: 1.4648394\ttotal: 4m 22s\tremaining: 3m 11s\n",
      "578:\tlearn: 1.4647201\ttotal: 4m 22s\tremaining: 3m 11s\n",
      "579:\tlearn: 1.4646862\ttotal: 4m 23s\tremaining: 3m 10s\n",
      "580:\tlearn: 1.4646165\ttotal: 4m 23s\tremaining: 3m 10s\n",
      "581:\tlearn: 1.4644998\ttotal: 4m 23s\tremaining: 3m 9s\n",
      "582:\tlearn: 1.4644164\ttotal: 4m 24s\tremaining: 3m 9s\n",
      "583:\tlearn: 1.4643526\ttotal: 4m 24s\tremaining: 3m 8s\n",
      "584:\tlearn: 1.4643080\ttotal: 4m 25s\tremaining: 3m 8s\n",
      "585:\tlearn: 1.4641937\ttotal: 4m 25s\tremaining: 3m 7s\n",
      "586:\tlearn: 1.4640817\ttotal: 4m 26s\tremaining: 3m 7s\n",
      "587:\tlearn: 1.4640311\ttotal: 4m 26s\tremaining: 3m 6s\n",
      "588:\tlearn: 1.4639334\ttotal: 4m 27s\tremaining: 3m 6s\n",
      "589:\tlearn: 1.4638308\ttotal: 4m 27s\tremaining: 3m 5s\n",
      "590:\tlearn: 1.4637791\ttotal: 4m 27s\tremaining: 3m 5s\n",
      "591:\tlearn: 1.4636886\ttotal: 4m 28s\tremaining: 3m 4s\n",
      "592:\tlearn: 1.4636221\ttotal: 4m 28s\tremaining: 3m 4s\n",
      "593:\tlearn: 1.4635537\ttotal: 4m 29s\tremaining: 3m 3s\n",
      "594:\tlearn: 1.4634750\ttotal: 4m 29s\tremaining: 3m 3s\n",
      "595:\tlearn: 1.4634111\ttotal: 4m 30s\tremaining: 3m 3s\n",
      "596:\tlearn: 1.4633907\ttotal: 4m 30s\tremaining: 3m 2s\n",
      "597:\tlearn: 1.4633325\ttotal: 4m 30s\tremaining: 3m 2s\n",
      "598:\tlearn: 1.4633013\ttotal: 4m 31s\tremaining: 3m 1s\n",
      "599:\tlearn: 1.4632203\ttotal: 4m 31s\tremaining: 3m 1s\n",
      "600:\tlearn: 1.4630873\ttotal: 4m 32s\tremaining: 3m\n",
      "601:\tlearn: 1.4629174\ttotal: 4m 32s\tremaining: 3m\n",
      "602:\tlearn: 1.4627655\ttotal: 4m 33s\tremaining: 2m 59s\n",
      "603:\tlearn: 1.4627020\ttotal: 4m 33s\tremaining: 2m 59s\n",
      "604:\tlearn: 1.4625863\ttotal: 4m 33s\tremaining: 2m 58s\n",
      "605:\tlearn: 1.4625150\ttotal: 4m 34s\tremaining: 2m 58s\n",
      "606:\tlearn: 1.4624305\ttotal: 4m 34s\tremaining: 2m 57s\n",
      "607:\tlearn: 1.4623337\ttotal: 4m 35s\tremaining: 2m 57s\n",
      "608:\tlearn: 1.4623068\ttotal: 4m 35s\tremaining: 2m 56s\n",
      "609:\tlearn: 1.4622221\ttotal: 4m 36s\tremaining: 2m 56s\n",
      "610:\tlearn: 1.4621235\ttotal: 4m 36s\tremaining: 2m 56s\n",
      "611:\tlearn: 1.4620389\ttotal: 4m 36s\tremaining: 2m 55s\n",
      "612:\tlearn: 1.4619761\ttotal: 4m 37s\tremaining: 2m 55s\n",
      "613:\tlearn: 1.4618928\ttotal: 4m 37s\tremaining: 2m 54s\n",
      "614:\tlearn: 1.4617785\ttotal: 4m 38s\tremaining: 2m 54s\n",
      "615:\tlearn: 1.4617455\ttotal: 4m 38s\tremaining: 2m 53s\n",
      "616:\tlearn: 1.4616054\ttotal: 4m 39s\tremaining: 2m 53s\n",
      "617:\tlearn: 1.4615355\ttotal: 4m 39s\tremaining: 2m 52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618:\tlearn: 1.4614854\ttotal: 4m 39s\tremaining: 2m 52s\n",
      "619:\tlearn: 1.4614404\ttotal: 4m 40s\tremaining: 2m 51s\n",
      "620:\tlearn: 1.4613746\ttotal: 4m 40s\tremaining: 2m 51s\n",
      "621:\tlearn: 1.4613113\ttotal: 4m 41s\tremaining: 2m 50s\n",
      "622:\tlearn: 1.4611822\ttotal: 4m 41s\tremaining: 2m 50s\n",
      "623:\tlearn: 1.4610930\ttotal: 4m 42s\tremaining: 2m 49s\n",
      "624:\tlearn: 1.4609779\ttotal: 4m 42s\tremaining: 2m 49s\n",
      "625:\tlearn: 1.4609488\ttotal: 4m 42s\tremaining: 2m 49s\n",
      "626:\tlearn: 1.4608789\ttotal: 4m 43s\tremaining: 2m 48s\n",
      "627:\tlearn: 1.4608009\ttotal: 4m 43s\tremaining: 2m 48s\n",
      "628:\tlearn: 1.4607244\ttotal: 4m 44s\tremaining: 2m 47s\n",
      "629:\tlearn: 1.4606762\ttotal: 4m 44s\tremaining: 2m 47s\n",
      "630:\tlearn: 1.4606058\ttotal: 4m 45s\tremaining: 2m 46s\n",
      "631:\tlearn: 1.4605055\ttotal: 4m 45s\tremaining: 2m 46s\n",
      "632:\tlearn: 1.4603665\ttotal: 4m 45s\tremaining: 2m 45s\n",
      "633:\tlearn: 1.4603234\ttotal: 4m 46s\tremaining: 2m 45s\n",
      "634:\tlearn: 1.4602725\ttotal: 4m 46s\tremaining: 2m 44s\n",
      "635:\tlearn: 1.4601956\ttotal: 4m 47s\tremaining: 2m 44s\n",
      "636:\tlearn: 1.4600571\ttotal: 4m 47s\tremaining: 2m 43s\n",
      "637:\tlearn: 1.4599955\ttotal: 4m 48s\tremaining: 2m 43s\n",
      "638:\tlearn: 1.4599242\ttotal: 4m 48s\tremaining: 2m 42s\n",
      "639:\tlearn: 1.4598302\ttotal: 4m 48s\tremaining: 2m 42s\n",
      "640:\tlearn: 1.4597777\ttotal: 4m 49s\tremaining: 2m 42s\n",
      "641:\tlearn: 1.4597223\ttotal: 4m 49s\tremaining: 2m 41s\n",
      "642:\tlearn: 1.4596333\ttotal: 4m 50s\tremaining: 2m 41s\n",
      "643:\tlearn: 1.4594942\ttotal: 4m 50s\tremaining: 2m 40s\n",
      "644:\tlearn: 1.4593261\ttotal: 4m 51s\tremaining: 2m 40s\n",
      "645:\tlearn: 1.4592349\ttotal: 4m 51s\tremaining: 2m 39s\n",
      "646:\tlearn: 1.4592017\ttotal: 4m 51s\tremaining: 2m 39s\n",
      "647:\tlearn: 1.4591285\ttotal: 4m 52s\tremaining: 2m 38s\n",
      "648:\tlearn: 1.4590361\ttotal: 4m 52s\tremaining: 2m 38s\n",
      "649:\tlearn: 1.4589660\ttotal: 4m 53s\tremaining: 2m 37s\n",
      "650:\tlearn: 1.4589345\ttotal: 4m 53s\tremaining: 2m 37s\n",
      "651:\tlearn: 1.4588449\ttotal: 4m 53s\tremaining: 2m 36s\n",
      "652:\tlearn: 1.4587136\ttotal: 4m 54s\tremaining: 2m 36s\n",
      "653:\tlearn: 1.4586340\ttotal: 4m 54s\tremaining: 2m 35s\n",
      "654:\tlearn: 1.4585630\ttotal: 4m 55s\tremaining: 2m 35s\n",
      "655:\tlearn: 1.4584394\ttotal: 4m 55s\tremaining: 2m 35s\n",
      "656:\tlearn: 1.4582984\ttotal: 4m 56s\tremaining: 2m 34s\n",
      "657:\tlearn: 1.4582298\ttotal: 4m 56s\tremaining: 2m 34s\n",
      "658:\tlearn: 1.4581447\ttotal: 4m 56s\tremaining: 2m 33s\n",
      "659:\tlearn: 1.4580623\ttotal: 4m 57s\tremaining: 2m 33s\n",
      "660:\tlearn: 1.4580084\ttotal: 4m 57s\tremaining: 2m 32s\n",
      "661:\tlearn: 1.4579142\ttotal: 4m 58s\tremaining: 2m 32s\n",
      "662:\tlearn: 1.4578640\ttotal: 4m 58s\tremaining: 2m 31s\n",
      "663:\tlearn: 1.4578049\ttotal: 4m 59s\tremaining: 2m 31s\n",
      "664:\tlearn: 1.4577666\ttotal: 4m 59s\tremaining: 2m 30s\n",
      "665:\tlearn: 1.4576847\ttotal: 5m\tremaining: 2m 30s\n",
      "666:\tlearn: 1.4576408\ttotal: 5m\tremaining: 2m 29s\n",
      "667:\tlearn: 1.4575817\ttotal: 5m\tremaining: 2m 29s\n",
      "668:\tlearn: 1.4575390\ttotal: 5m 1s\tremaining: 2m 29s\n",
      "669:\tlearn: 1.4574633\ttotal: 5m 1s\tremaining: 2m 28s\n",
      "670:\tlearn: 1.4573821\ttotal: 5m 2s\tremaining: 2m 28s\n",
      "671:\tlearn: 1.4573044\ttotal: 5m 2s\tremaining: 2m 27s\n",
      "672:\tlearn: 1.4572024\ttotal: 5m 3s\tremaining: 2m 27s\n",
      "673:\tlearn: 1.4571514\ttotal: 5m 3s\tremaining: 2m 26s\n",
      "674:\tlearn: 1.4570709\ttotal: 5m 3s\tremaining: 2m 26s\n",
      "675:\tlearn: 1.4569719\ttotal: 5m 4s\tremaining: 2m 25s\n",
      "676:\tlearn: 1.4568816\ttotal: 5m 4s\tremaining: 2m 25s\n",
      "677:\tlearn: 1.4567965\ttotal: 5m 5s\tremaining: 2m 24s\n",
      "678:\tlearn: 1.4567781\ttotal: 5m 5s\tremaining: 2m 24s\n",
      "679:\tlearn: 1.4567279\ttotal: 5m 6s\tremaining: 2m 24s\n",
      "680:\tlearn: 1.4566539\ttotal: 5m 6s\tremaining: 2m 23s\n",
      "681:\tlearn: 1.4565446\ttotal: 5m 6s\tremaining: 2m 23s\n",
      "682:\tlearn: 1.4564694\ttotal: 5m 7s\tremaining: 2m 22s\n",
      "683:\tlearn: 1.4563938\ttotal: 5m 7s\tremaining: 2m 22s\n",
      "684:\tlearn: 1.4562807\ttotal: 5m 8s\tremaining: 2m 21s\n",
      "685:\tlearn: 1.4562291\ttotal: 5m 8s\tremaining: 2m 21s\n",
      "686:\tlearn: 1.4561224\ttotal: 5m 9s\tremaining: 2m 20s\n",
      "687:\tlearn: 1.4560582\ttotal: 5m 9s\tremaining: 2m 20s\n",
      "688:\tlearn: 1.4559743\ttotal: 5m 10s\tremaining: 2m 19s\n",
      "689:\tlearn: 1.4558942\ttotal: 5m 10s\tremaining: 2m 19s\n",
      "690:\tlearn: 1.4558383\ttotal: 5m 10s\tremaining: 2m 19s\n",
      "691:\tlearn: 1.4557893\ttotal: 5m 11s\tremaining: 2m 18s\n",
      "692:\tlearn: 1.4557415\ttotal: 5m 11s\tremaining: 2m 18s\n",
      "693:\tlearn: 1.4556634\ttotal: 5m 12s\tremaining: 2m 17s\n",
      "694:\tlearn: 1.4555731\ttotal: 5m 12s\tremaining: 2m 17s\n",
      "695:\tlearn: 1.4555509\ttotal: 5m 13s\tremaining: 2m 16s\n",
      "696:\tlearn: 1.4554795\ttotal: 5m 13s\tremaining: 2m 16s\n",
      "697:\tlearn: 1.4554333\ttotal: 5m 14s\tremaining: 2m 15s\n",
      "698:\tlearn: 1.4553901\ttotal: 5m 14s\tremaining: 2m 15s\n",
      "699:\tlearn: 1.4552882\ttotal: 5m 14s\tremaining: 2m 14s\n",
      "700:\tlearn: 1.4551961\ttotal: 5m 15s\tremaining: 2m 14s\n",
      "701:\tlearn: 1.4551456\ttotal: 5m 15s\tremaining: 2m 14s\n",
      "702:\tlearn: 1.4550837\ttotal: 5m 16s\tremaining: 2m 13s\n",
      "703:\tlearn: 1.4550080\ttotal: 5m 16s\tremaining: 2m 13s\n",
      "704:\tlearn: 1.4549398\ttotal: 5m 17s\tremaining: 2m 12s\n",
      "705:\tlearn: 1.4548844\ttotal: 5m 17s\tremaining: 2m 12s\n",
      "706:\tlearn: 1.4548611\ttotal: 5m 17s\tremaining: 2m 11s\n",
      "707:\tlearn: 1.4547847\ttotal: 5m 18s\tremaining: 2m 11s\n",
      "708:\tlearn: 1.4546570\ttotal: 5m 18s\tremaining: 2m 10s\n",
      "709:\tlearn: 1.4545513\ttotal: 5m 19s\tremaining: 2m 10s\n",
      "710:\tlearn: 1.4544952\ttotal: 5m 19s\tremaining: 2m 9s\n",
      "711:\tlearn: 1.4544219\ttotal: 5m 20s\tremaining: 2m 9s\n",
      "712:\tlearn: 1.4543316\ttotal: 5m 20s\tremaining: 2m 9s\n",
      "713:\tlearn: 1.4542511\ttotal: 5m 21s\tremaining: 2m 8s\n",
      "714:\tlearn: 1.4541910\ttotal: 5m 21s\tremaining: 2m 8s\n",
      "715:\tlearn: 1.4541401\ttotal: 5m 22s\tremaining: 2m 7s\n",
      "716:\tlearn: 1.4540620\ttotal: 5m 22s\tremaining: 2m 7s\n",
      "717:\tlearn: 1.4539749\ttotal: 5m 22s\tremaining: 2m 6s\n",
      "718:\tlearn: 1.4539311\ttotal: 5m 23s\tremaining: 2m 6s\n",
      "719:\tlearn: 1.4537799\ttotal: 5m 23s\tremaining: 2m 5s\n",
      "720:\tlearn: 1.4537463\ttotal: 5m 24s\tremaining: 2m 5s\n",
      "721:\tlearn: 1.4537024\ttotal: 5m 24s\tremaining: 2m 5s\n",
      "722:\tlearn: 1.4535905\ttotal: 5m 25s\tremaining: 2m 4s\n",
      "723:\tlearn: 1.4535265\ttotal: 5m 25s\tremaining: 2m 4s\n",
      "724:\tlearn: 1.4534806\ttotal: 5m 25s\tremaining: 2m 3s\n",
      "725:\tlearn: 1.4534449\ttotal: 5m 26s\tremaining: 2m 3s\n",
      "726:\tlearn: 1.4533715\ttotal: 5m 26s\tremaining: 2m 2s\n",
      "727:\tlearn: 1.4533339\ttotal: 5m 27s\tremaining: 2m 2s\n",
      "728:\tlearn: 1.4532560\ttotal: 5m 27s\tremaining: 2m 1s\n",
      "729:\tlearn: 1.4531670\ttotal: 5m 28s\tremaining: 2m 1s\n",
      "730:\tlearn: 1.4531082\ttotal: 5m 28s\tremaining: 2m\n",
      "731:\tlearn: 1.4530448\ttotal: 5m 28s\tremaining: 2m\n",
      "732:\tlearn: 1.4529896\ttotal: 5m 29s\tremaining: 1m 59s\n",
      "733:\tlearn: 1.4529530\ttotal: 5m 29s\tremaining: 1m 59s\n",
      "734:\tlearn: 1.4528787\ttotal: 5m 30s\tremaining: 1m 59s\n",
      "735:\tlearn: 1.4528267\ttotal: 5m 30s\tremaining: 1m 58s\n",
      "736:\tlearn: 1.4527760\ttotal: 5m 31s\tremaining: 1m 58s\n",
      "737:\tlearn: 1.4527100\ttotal: 5m 31s\tremaining: 1m 57s\n",
      "738:\tlearn: 1.4526622\ttotal: 5m 32s\tremaining: 1m 57s\n",
      "739:\tlearn: 1.4525961\ttotal: 5m 32s\tremaining: 1m 56s\n",
      "740:\tlearn: 1.4525252\ttotal: 5m 32s\tremaining: 1m 56s\n",
      "741:\tlearn: 1.4524386\ttotal: 5m 33s\tremaining: 1m 55s\n",
      "742:\tlearn: 1.4522946\ttotal: 5m 33s\tremaining: 1m 55s\n",
      "743:\tlearn: 1.4522517\ttotal: 5m 34s\tremaining: 1m 54s\n",
      "744:\tlearn: 1.4522059\ttotal: 5m 34s\tremaining: 1m 54s\n",
      "745:\tlearn: 1.4521206\ttotal: 5m 35s\tremaining: 1m 54s\n",
      "746:\tlearn: 1.4520812\ttotal: 5m 35s\tremaining: 1m 53s\n",
      "747:\tlearn: 1.4520324\ttotal: 5m 35s\tremaining: 1m 53s\n",
      "748:\tlearn: 1.4519460\ttotal: 5m 36s\tremaining: 1m 52s\n",
      "749:\tlearn: 1.4518895\ttotal: 5m 36s\tremaining: 1m 52s\n",
      "750:\tlearn: 1.4518527\ttotal: 5m 37s\tremaining: 1m 51s\n",
      "751:\tlearn: 1.4518129\ttotal: 5m 37s\tremaining: 1m 51s\n",
      "752:\tlearn: 1.4517669\ttotal: 5m 38s\tremaining: 1m 50s\n",
      "753:\tlearn: 1.4516887\ttotal: 5m 38s\tremaining: 1m 50s\n",
      "754:\tlearn: 1.4516274\ttotal: 5m 38s\tremaining: 1m 49s\n",
      "755:\tlearn: 1.4515717\ttotal: 5m 39s\tremaining: 1m 49s\n",
      "756:\tlearn: 1.4514898\ttotal: 5m 39s\tremaining: 1m 49s\n",
      "757:\tlearn: 1.4514200\ttotal: 5m 40s\tremaining: 1m 48s\n",
      "758:\tlearn: 1.4513806\ttotal: 5m 40s\tremaining: 1m 48s\n",
      "759:\tlearn: 1.4513324\ttotal: 5m 41s\tremaining: 1m 47s\n",
      "760:\tlearn: 1.4512813\ttotal: 5m 41s\tremaining: 1m 47s\n",
      "761:\tlearn: 1.4511822\ttotal: 5m 41s\tremaining: 1m 46s\n",
      "762:\tlearn: 1.4511209\ttotal: 5m 42s\tremaining: 1m 46s\n",
      "763:\tlearn: 1.4510326\ttotal: 5m 42s\tremaining: 1m 45s\n",
      "764:\tlearn: 1.4509617\ttotal: 5m 43s\tremaining: 1m 45s\n",
      "765:\tlearn: 1.4508451\ttotal: 5m 43s\tremaining: 1m 44s\n",
      "766:\tlearn: 1.4507871\ttotal: 5m 44s\tremaining: 1m 44s\n",
      "767:\tlearn: 1.4506880\ttotal: 5m 44s\tremaining: 1m 44s\n",
      "768:\tlearn: 1.4506153\ttotal: 5m 44s\tremaining: 1m 43s\n",
      "769:\tlearn: 1.4505145\ttotal: 5m 45s\tremaining: 1m 43s\n",
      "770:\tlearn: 1.4504638\ttotal: 5m 45s\tremaining: 1m 42s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "771:\tlearn: 1.4503769\ttotal: 5m 46s\tremaining: 1m 42s\n",
      "772:\tlearn: 1.4502914\ttotal: 5m 46s\tremaining: 1m 41s\n",
      "773:\tlearn: 1.4501738\ttotal: 5m 47s\tremaining: 1m 41s\n",
      "774:\tlearn: 1.4500918\ttotal: 5m 47s\tremaining: 1m 40s\n",
      "775:\tlearn: 1.4500045\ttotal: 5m 48s\tremaining: 1m 40s\n",
      "776:\tlearn: 1.4499127\ttotal: 5m 48s\tremaining: 1m 40s\n",
      "777:\tlearn: 1.4498779\ttotal: 5m 49s\tremaining: 1m 39s\n",
      "778:\tlearn: 1.4497852\ttotal: 5m 49s\tremaining: 1m 39s\n",
      "779:\tlearn: 1.4496715\ttotal: 5m 49s\tremaining: 1m 38s\n",
      "780:\tlearn: 1.4495989\ttotal: 5m 50s\tremaining: 1m 38s\n",
      "781:\tlearn: 1.4495628\ttotal: 5m 50s\tremaining: 1m 37s\n",
      "782:\tlearn: 1.4494055\ttotal: 5m 51s\tremaining: 1m 37s\n",
      "783:\tlearn: 1.4493627\ttotal: 5m 51s\tremaining: 1m 36s\n",
      "784:\tlearn: 1.4493189\ttotal: 5m 52s\tremaining: 1m 36s\n",
      "785:\tlearn: 1.4492949\ttotal: 5m 52s\tremaining: 1m 36s\n",
      "786:\tlearn: 1.4492268\ttotal: 5m 53s\tremaining: 1m 35s\n",
      "787:\tlearn: 1.4491535\ttotal: 5m 53s\tremaining: 1m 35s\n",
      "788:\tlearn: 1.4490638\ttotal: 5m 53s\tremaining: 1m 34s\n",
      "789:\tlearn: 1.4489986\ttotal: 5m 54s\tremaining: 1m 34s\n",
      "790:\tlearn: 1.4489645\ttotal: 5m 54s\tremaining: 1m 33s\n",
      "791:\tlearn: 1.4488506\ttotal: 5m 55s\tremaining: 1m 33s\n",
      "792:\tlearn: 1.4487534\ttotal: 5m 55s\tremaining: 1m 32s\n",
      "793:\tlearn: 1.4486864\ttotal: 5m 56s\tremaining: 1m 32s\n",
      "794:\tlearn: 1.4485770\ttotal: 5m 56s\tremaining: 1m 31s\n",
      "795:\tlearn: 1.4484686\ttotal: 5m 56s\tremaining: 1m 31s\n",
      "796:\tlearn: 1.4483952\ttotal: 5m 57s\tremaining: 1m 31s\n",
      "797:\tlearn: 1.4483332\ttotal: 5m 57s\tremaining: 1m 30s\n",
      "798:\tlearn: 1.4482316\ttotal: 5m 58s\tremaining: 1m 30s\n",
      "799:\tlearn: 1.4481457\ttotal: 5m 58s\tremaining: 1m 29s\n",
      "800:\tlearn: 1.4480553\ttotal: 5m 58s\tremaining: 1m 29s\n",
      "801:\tlearn: 1.4480040\ttotal: 5m 59s\tremaining: 1m 28s\n",
      "802:\tlearn: 1.4479597\ttotal: 5m 59s\tremaining: 1m 28s\n",
      "803:\tlearn: 1.4478990\ttotal: 6m\tremaining: 1m 27s\n",
      "804:\tlearn: 1.4478032\ttotal: 6m\tremaining: 1m 27s\n",
      "805:\tlearn: 1.4477274\ttotal: 6m 1s\tremaining: 1m 26s\n",
      "806:\tlearn: 1.4476499\ttotal: 6m 1s\tremaining: 1m 26s\n",
      "807:\tlearn: 1.4475466\ttotal: 6m 2s\tremaining: 1m 26s\n",
      "808:\tlearn: 1.4474757\ttotal: 6m 2s\tremaining: 1m 25s\n",
      "809:\tlearn: 1.4474416\ttotal: 6m 2s\tremaining: 1m 25s\n",
      "810:\tlearn: 1.4474057\ttotal: 6m 3s\tremaining: 1m 24s\n",
      "811:\tlearn: 1.4472949\ttotal: 6m 3s\tremaining: 1m 24s\n",
      "812:\tlearn: 1.4472196\ttotal: 6m 4s\tremaining: 1m 23s\n",
      "813:\tlearn: 1.4471835\ttotal: 6m 4s\tremaining: 1m 23s\n",
      "814:\tlearn: 1.4471136\ttotal: 6m 5s\tremaining: 1m 22s\n",
      "815:\tlearn: 1.4470346\ttotal: 6m 5s\tremaining: 1m 22s\n",
      "816:\tlearn: 1.4469806\ttotal: 6m 5s\tremaining: 1m 21s\n",
      "817:\tlearn: 1.4469069\ttotal: 6m 6s\tremaining: 1m 21s\n",
      "818:\tlearn: 1.4468579\ttotal: 6m 6s\tremaining: 1m 21s\n",
      "819:\tlearn: 1.4467632\ttotal: 6m 7s\tremaining: 1m 20s\n",
      "820:\tlearn: 1.4467349\ttotal: 6m 7s\tremaining: 1m 20s\n",
      "821:\tlearn: 1.4466824\ttotal: 6m 7s\tremaining: 1m 19s\n",
      "822:\tlearn: 1.4465923\ttotal: 6m 8s\tremaining: 1m 19s\n",
      "823:\tlearn: 1.4465396\ttotal: 6m 8s\tremaining: 1m 18s\n",
      "824:\tlearn: 1.4464753\ttotal: 6m 9s\tremaining: 1m 18s\n",
      "825:\tlearn: 1.4464039\ttotal: 6m 9s\tremaining: 1m 17s\n",
      "826:\tlearn: 1.4463690\ttotal: 6m 10s\tremaining: 1m 17s\n",
      "827:\tlearn: 1.4462955\ttotal: 6m 10s\tremaining: 1m 16s\n",
      "828:\tlearn: 1.4462483\ttotal: 6m 10s\tremaining: 1m 16s\n",
      "829:\tlearn: 1.4461973\ttotal: 6m 11s\tremaining: 1m 16s\n",
      "830:\tlearn: 1.4461658\ttotal: 6m 11s\tremaining: 1m 15s\n",
      "831:\tlearn: 1.4460926\ttotal: 6m 12s\tremaining: 1m 15s\n",
      "832:\tlearn: 1.4460411\ttotal: 6m 12s\tremaining: 1m 14s\n",
      "833:\tlearn: 1.4459456\ttotal: 6m 13s\tremaining: 1m 14s\n",
      "834:\tlearn: 1.4458642\ttotal: 6m 13s\tremaining: 1m 13s\n",
      "835:\tlearn: 1.4458147\ttotal: 6m 13s\tremaining: 1m 13s\n",
      "836:\tlearn: 1.4456793\ttotal: 6m 14s\tremaining: 1m 12s\n",
      "837:\tlearn: 1.4456126\ttotal: 6m 14s\tremaining: 1m 12s\n",
      "838:\tlearn: 1.4455719\ttotal: 6m 15s\tremaining: 1m 11s\n",
      "839:\tlearn: 1.4454571\ttotal: 6m 15s\tremaining: 1m 11s\n",
      "840:\tlearn: 1.4453837\ttotal: 6m 16s\tremaining: 1m 11s\n",
      "841:\tlearn: 1.4453080\ttotal: 6m 16s\tremaining: 1m 10s\n",
      "842:\tlearn: 1.4452611\ttotal: 6m 16s\tremaining: 1m 10s\n",
      "843:\tlearn: 1.4452078\ttotal: 6m 17s\tremaining: 1m 9s\n",
      "844:\tlearn: 1.4451146\ttotal: 6m 17s\tremaining: 1m 9s\n",
      "845:\tlearn: 1.4449705\ttotal: 6m 18s\tremaining: 1m 8s\n",
      "846:\tlearn: 1.4448680\ttotal: 6m 18s\tremaining: 1m 8s\n",
      "847:\tlearn: 1.4447478\ttotal: 6m 18s\tremaining: 1m 7s\n",
      "848:\tlearn: 1.4446892\ttotal: 6m 19s\tremaining: 1m 7s\n",
      "849:\tlearn: 1.4446702\ttotal: 6m 19s\tremaining: 1m 7s\n",
      "850:\tlearn: 1.4445966\ttotal: 6m 20s\tremaining: 1m 6s\n",
      "851:\tlearn: 1.4444883\ttotal: 6m 20s\tremaining: 1m 6s\n",
      "852:\tlearn: 1.4444103\ttotal: 6m 21s\tremaining: 1m 5s\n",
      "853:\tlearn: 1.4443529\ttotal: 6m 21s\tremaining: 1m 5s\n",
      "854:\tlearn: 1.4443313\ttotal: 6m 21s\tremaining: 1m 4s\n",
      "855:\tlearn: 1.4441836\ttotal: 6m 22s\tremaining: 1m 4s\n",
      "856:\tlearn: 1.4441368\ttotal: 6m 22s\tremaining: 1m 3s\n",
      "857:\tlearn: 1.4440537\ttotal: 6m 23s\tremaining: 1m 3s\n",
      "858:\tlearn: 1.4439867\ttotal: 6m 23s\tremaining: 1m 2s\n",
      "859:\tlearn: 1.4439059\ttotal: 6m 24s\tremaining: 1m 2s\n",
      "860:\tlearn: 1.4438314\ttotal: 6m 24s\tremaining: 1m 2s\n",
      "861:\tlearn: 1.4437747\ttotal: 6m 24s\tremaining: 1m 1s\n",
      "862:\tlearn: 1.4437161\ttotal: 6m 25s\tremaining: 1m 1s\n",
      "863:\tlearn: 1.4436870\ttotal: 6m 25s\tremaining: 1m\n",
      "864:\tlearn: 1.4436274\ttotal: 6m 26s\tremaining: 1m\n",
      "865:\tlearn: 1.4435496\ttotal: 6m 26s\tremaining: 59.8s\n",
      "866:\tlearn: 1.4434835\ttotal: 6m 27s\tremaining: 59.4s\n",
      "867:\tlearn: 1.4434292\ttotal: 6m 27s\tremaining: 58.9s\n",
      "868:\tlearn: 1.4433801\ttotal: 6m 27s\tremaining: 58.5s\n",
      "869:\tlearn: 1.4433365\ttotal: 6m 28s\tremaining: 58s\n",
      "870:\tlearn: 1.4433190\ttotal: 6m 28s\tremaining: 57.6s\n",
      "871:\tlearn: 1.4432144\ttotal: 6m 29s\tremaining: 57.1s\n",
      "872:\tlearn: 1.4431743\ttotal: 6m 29s\tremaining: 56.7s\n",
      "873:\tlearn: 1.4430944\ttotal: 6m 30s\tremaining: 56.2s\n",
      "874:\tlearn: 1.4430346\ttotal: 6m 30s\tremaining: 55.8s\n",
      "875:\tlearn: 1.4429584\ttotal: 6m 30s\tremaining: 55.3s\n",
      "876:\tlearn: 1.4429046\ttotal: 6m 31s\tremaining: 54.9s\n",
      "877:\tlearn: 1.4428521\ttotal: 6m 31s\tremaining: 54.4s\n",
      "878:\tlearn: 1.4427762\ttotal: 6m 32s\tremaining: 54s\n",
      "879:\tlearn: 1.4426846\ttotal: 6m 32s\tremaining: 53.5s\n",
      "880:\tlearn: 1.4426406\ttotal: 6m 33s\tremaining: 53.1s\n",
      "881:\tlearn: 1.4425554\ttotal: 6m 33s\tremaining: 52.6s\n",
      "882:\tlearn: 1.4425326\ttotal: 6m 33s\tremaining: 52.2s\n",
      "883:\tlearn: 1.4425132\ttotal: 6m 34s\tremaining: 51.7s\n",
      "884:\tlearn: 1.4424570\ttotal: 6m 34s\tremaining: 51.3s\n",
      "885:\tlearn: 1.4424092\ttotal: 6m 35s\tremaining: 50.8s\n",
      "886:\tlearn: 1.4423255\ttotal: 6m 35s\tremaining: 50.4s\n",
      "887:\tlearn: 1.4422536\ttotal: 6m 36s\tremaining: 49.9s\n",
      "888:\tlearn: 1.4422283\ttotal: 6m 36s\tremaining: 49.5s\n",
      "889:\tlearn: 1.4420758\ttotal: 6m 36s\tremaining: 49.1s\n",
      "890:\tlearn: 1.4420211\ttotal: 6m 37s\tremaining: 48.6s\n",
      "891:\tlearn: 1.4419262\ttotal: 6m 37s\tremaining: 48.2s\n",
      "892:\tlearn: 1.4418294\ttotal: 6m 38s\tremaining: 47.7s\n",
      "893:\tlearn: 1.4417420\ttotal: 6m 38s\tremaining: 47.3s\n",
      "894:\tlearn: 1.4416435\ttotal: 6m 39s\tremaining: 46.8s\n",
      "895:\tlearn: 1.4415544\ttotal: 6m 39s\tremaining: 46.4s\n",
      "896:\tlearn: 1.4415297\ttotal: 6m 39s\tremaining: 45.9s\n",
      "897:\tlearn: 1.4414739\ttotal: 6m 40s\tremaining: 45.5s\n",
      "898:\tlearn: 1.4413821\ttotal: 6m 40s\tremaining: 45s\n",
      "899:\tlearn: 1.4413206\ttotal: 6m 41s\tremaining: 44.6s\n",
      "900:\tlearn: 1.4412514\ttotal: 6m 41s\tremaining: 44.1s\n",
      "901:\tlearn: 1.4411729\ttotal: 6m 42s\tremaining: 43.7s\n",
      "902:\tlearn: 1.4410957\ttotal: 6m 42s\tremaining: 43.2s\n",
      "903:\tlearn: 1.4409935\ttotal: 6m 42s\tremaining: 42.8s\n",
      "904:\tlearn: 1.4409168\ttotal: 6m 43s\tremaining: 42.3s\n",
      "905:\tlearn: 1.4408480\ttotal: 6m 43s\tremaining: 41.9s\n",
      "906:\tlearn: 1.4407424\ttotal: 6m 44s\tremaining: 41.4s\n",
      "907:\tlearn: 1.4406785\ttotal: 6m 44s\tremaining: 41s\n",
      "908:\tlearn: 1.4406166\ttotal: 6m 45s\tremaining: 40.5s\n",
      "909:\tlearn: 1.4405605\ttotal: 6m 45s\tremaining: 40.1s\n",
      "910:\tlearn: 1.4404701\ttotal: 6m 45s\tremaining: 39.7s\n",
      "911:\tlearn: 1.4404004\ttotal: 6m 46s\tremaining: 39.2s\n",
      "912:\tlearn: 1.4403410\ttotal: 6m 46s\tremaining: 38.8s\n",
      "913:\tlearn: 1.4402857\ttotal: 6m 47s\tremaining: 38.3s\n",
      "914:\tlearn: 1.4402015\ttotal: 6m 47s\tremaining: 37.9s\n",
      "915:\tlearn: 1.4401683\ttotal: 6m 47s\tremaining: 37.4s\n",
      "916:\tlearn: 1.4401354\ttotal: 6m 48s\tremaining: 37s\n",
      "917:\tlearn: 1.4401016\ttotal: 6m 48s\tremaining: 36.5s\n",
      "918:\tlearn: 1.4400153\ttotal: 6m 49s\tremaining: 36.1s\n",
      "919:\tlearn: 1.4399857\ttotal: 6m 49s\tremaining: 35.6s\n",
      "920:\tlearn: 1.4399022\ttotal: 6m 50s\tremaining: 35.2s\n",
      "921:\tlearn: 1.4398268\ttotal: 6m 50s\tremaining: 34.7s\n",
      "922:\tlearn: 1.4397866\ttotal: 6m 50s\tremaining: 34.3s\n",
      "923:\tlearn: 1.4397162\ttotal: 6m 51s\tremaining: 33.8s\n",
      "924:\tlearn: 1.4396975\ttotal: 6m 51s\tremaining: 33.4s\n",
      "925:\tlearn: 1.4396263\ttotal: 6m 52s\tremaining: 32.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "926:\tlearn: 1.4395114\ttotal: 6m 52s\tremaining: 32.5s\n",
      "927:\tlearn: 1.4394763\ttotal: 6m 53s\tremaining: 32.1s\n",
      "928:\tlearn: 1.4394510\ttotal: 6m 53s\tremaining: 31.6s\n",
      "929:\tlearn: 1.4394002\ttotal: 6m 53s\tremaining: 31.2s\n",
      "930:\tlearn: 1.4393613\ttotal: 6m 54s\tremaining: 30.7s\n",
      "931:\tlearn: 1.4393092\ttotal: 6m 54s\tremaining: 30.3s\n",
      "932:\tlearn: 1.4392099\ttotal: 6m 55s\tremaining: 29.8s\n",
      "933:\tlearn: 1.4391285\ttotal: 6m 55s\tremaining: 29.4s\n",
      "934:\tlearn: 1.4390454\ttotal: 6m 56s\tremaining: 28.9s\n",
      "935:\tlearn: 1.4389560\ttotal: 6m 56s\tremaining: 28.5s\n",
      "936:\tlearn: 1.4388838\ttotal: 6m 56s\tremaining: 28s\n",
      "937:\tlearn: 1.4388467\ttotal: 6m 57s\tremaining: 27.6s\n",
      "938:\tlearn: 1.4387893\ttotal: 6m 57s\tremaining: 27.1s\n",
      "939:\tlearn: 1.4387511\ttotal: 6m 58s\tremaining: 26.7s\n",
      "940:\tlearn: 1.4386704\ttotal: 6m 58s\tremaining: 26.3s\n",
      "941:\tlearn: 1.4386222\ttotal: 6m 59s\tremaining: 25.8s\n",
      "942:\tlearn: 1.4385471\ttotal: 6m 59s\tremaining: 25.4s\n",
      "943:\tlearn: 1.4384764\ttotal: 6m 59s\tremaining: 24.9s\n",
      "944:\tlearn: 1.4384403\ttotal: 7m\tremaining: 24.5s\n",
      "945:\tlearn: 1.4383706\ttotal: 7m\tremaining: 24s\n",
      "946:\tlearn: 1.4382701\ttotal: 7m 1s\tremaining: 23.6s\n",
      "947:\tlearn: 1.4382169\ttotal: 7m 1s\tremaining: 23.1s\n",
      "948:\tlearn: 1.4381320\ttotal: 7m 2s\tremaining: 22.7s\n",
      "949:\tlearn: 1.4380421\ttotal: 7m 2s\tremaining: 22.2s\n",
      "950:\tlearn: 1.4379878\ttotal: 7m 2s\tremaining: 21.8s\n",
      "951:\tlearn: 1.4379516\ttotal: 7m 3s\tremaining: 21.3s\n",
      "952:\tlearn: 1.4378926\ttotal: 7m 3s\tremaining: 20.9s\n",
      "953:\tlearn: 1.4378492\ttotal: 7m 4s\tremaining: 20.5s\n",
      "954:\tlearn: 1.4378114\ttotal: 7m 4s\tremaining: 20s\n",
      "955:\tlearn: 1.4377356\ttotal: 7m 5s\tremaining: 19.6s\n",
      "956:\tlearn: 1.4376889\ttotal: 7m 5s\tremaining: 19.1s\n",
      "957:\tlearn: 1.4376691\ttotal: 7m 5s\tremaining: 18.7s\n",
      "958:\tlearn: 1.4376259\ttotal: 7m 6s\tremaining: 18.2s\n",
      "959:\tlearn: 1.4375781\ttotal: 7m 6s\tremaining: 17.8s\n",
      "960:\tlearn: 1.4374988\ttotal: 7m 7s\tremaining: 17.3s\n",
      "961:\tlearn: 1.4374507\ttotal: 7m 7s\tremaining: 16.9s\n",
      "962:\tlearn: 1.4374132\ttotal: 7m 8s\tremaining: 16.4s\n",
      "963:\tlearn: 1.4373413\ttotal: 7m 8s\tremaining: 16s\n",
      "964:\tlearn: 1.4372958\ttotal: 7m 8s\tremaining: 15.6s\n",
      "965:\tlearn: 1.4372175\ttotal: 7m 9s\tremaining: 15.1s\n",
      "966:\tlearn: 1.4371295\ttotal: 7m 9s\tremaining: 14.7s\n",
      "967:\tlearn: 1.4371034\ttotal: 7m 10s\tremaining: 14.2s\n",
      "968:\tlearn: 1.4370259\ttotal: 7m 10s\tremaining: 13.8s\n",
      "969:\tlearn: 1.4369771\ttotal: 7m 11s\tremaining: 13.3s\n",
      "970:\tlearn: 1.4369185\ttotal: 7m 11s\tremaining: 12.9s\n",
      "971:\tlearn: 1.4368782\ttotal: 7m 11s\tremaining: 12.4s\n",
      "972:\tlearn: 1.4368225\ttotal: 7m 12s\tremaining: 12s\n",
      "973:\tlearn: 1.4367309\ttotal: 7m 12s\tremaining: 11.6s\n",
      "974:\tlearn: 1.4366911\ttotal: 7m 13s\tremaining: 11.1s\n",
      "975:\tlearn: 1.4366137\ttotal: 7m 13s\tremaining: 10.7s\n",
      "976:\tlearn: 1.4365715\ttotal: 7m 14s\tremaining: 10.2s\n",
      "977:\tlearn: 1.4364914\ttotal: 7m 14s\tremaining: 9.77s\n",
      "978:\tlearn: 1.4364237\ttotal: 7m 14s\tremaining: 9.33s\n",
      "979:\tlearn: 1.4363637\ttotal: 7m 15s\tremaining: 8.88s\n",
      "980:\tlearn: 1.4363001\ttotal: 7m 15s\tremaining: 8.44s\n",
      "981:\tlearn: 1.4362626\ttotal: 7m 16s\tremaining: 7.99s\n",
      "982:\tlearn: 1.4362374\ttotal: 7m 16s\tremaining: 7.55s\n",
      "983:\tlearn: 1.4361835\ttotal: 7m 17s\tremaining: 7.11s\n",
      "984:\tlearn: 1.4360943\ttotal: 7m 17s\tremaining: 6.66s\n",
      "985:\tlearn: 1.4360292\ttotal: 7m 17s\tremaining: 6.22s\n",
      "986:\tlearn: 1.4359244\ttotal: 7m 18s\tremaining: 5.77s\n",
      "987:\tlearn: 1.4358465\ttotal: 7m 18s\tremaining: 5.33s\n",
      "988:\tlearn: 1.4357583\ttotal: 7m 19s\tremaining: 4.88s\n",
      "989:\tlearn: 1.4357032\ttotal: 7m 19s\tremaining: 4.44s\n",
      "990:\tlearn: 1.4356499\ttotal: 7m 19s\tremaining: 4s\n",
      "991:\tlearn: 1.4355726\ttotal: 7m 20s\tremaining: 3.55s\n",
      "992:\tlearn: 1.4355085\ttotal: 7m 20s\tremaining: 3.11s\n",
      "993:\tlearn: 1.4354300\ttotal: 7m 21s\tremaining: 2.66s\n",
      "994:\tlearn: 1.4353654\ttotal: 7m 21s\tremaining: 2.22s\n",
      "995:\tlearn: 1.4353133\ttotal: 7m 22s\tremaining: 1.77s\n",
      "996:\tlearn: 1.4352550\ttotal: 7m 22s\tremaining: 1.33s\n",
      "997:\tlearn: 1.4351785\ttotal: 7m 22s\tremaining: 888ms\n",
      "998:\tlearn: 1.4351077\ttotal: 7m 23s\tremaining: 444ms\n",
      "999:\tlearn: 1.4349904\ttotal: 7m 23s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1ec04b92040>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmodel = CatBoostClassifier()\n",
    "dmodel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "headed-principle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model = 45.06 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Model = {:.2f} %\".format(dmodel.score(X,y) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "occasional-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = test['Stay']\n",
    "Xt = test.drop(columns=['Stay','Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "offshore-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dmodel.predict(Xt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accurate-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pd.DataFrame(test_df['case_id'])\n",
    "outputdf['Stay'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-grill",
   "metadata": {},
   "source": [
    "#### Store the output in \"final_submission.csv\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "existing-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf.to_csv(\"final_submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-outline",
   "metadata": {},
   "source": [
    "### The END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
